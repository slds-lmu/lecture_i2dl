
\input{../../2021/style/preamble_mina.tex}  
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\input{../../latex-math/ml-nn}

\begin{document}

\lecturechapter{5}{Variants of convolutions}
\lecture{Deeplearning}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Lecture outline}
\tableofcontents
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Padding}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{

\frametitle{Padding}

  \begin{itemize}

    \only<1-3>{\item \enquote{Valid} convolution without padding.}
    \only<1>{\item[] Exactly what we just did is called valid convolution. Suppose we have an input of size $5 \times 5$ and a filter of size $2$. }
    \only<2>{\item[] The filter is only allowed to move inside of the input space.}
    \only<3>{\item[] That will inevitably reduce the output dimensions.}
    
  \end{itemize}

  \center
  \only<1>{\scalebox{0.92}{\includegraphics{plots/05_conv_variations/valid/valid_conv_2.jpg}}}%
  \only<2>{\scalebox{1.05}{\includegraphics{plots/05_conv_variations/valid/valid_conv_3.jpg}}}%
  %\only<3>{\includegraphics[width=10cm]{plots/05_conv_variations/valid/valid2.png}}%
  %\only<4>{\includegraphics[width=10cm]{plots/05_conv_variations/valid/valid3.png}}%
  \only<3>{\scalebox{0.92}{\includegraphics{plots/05_conv_variations/valid/valid_conv_1n.png}}}%
  
  \only<3>{\item[] In general, for an input of size $i \:(\times \:i)$ and filter size $k \:(\times \:k)$, the size of the output feature map $o \:(\times \:o)$ claculated by:
    $$ o=  i-k + 1 $$ }
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\frame{

\frametitle{Padding}

  \begin{itemize}

    \only<1-4>{\item Convolution with \enquote{same} padding.}
    \only<1>{\item[] Suppose the following situation: an input with dimensions $5x5$ and a filter with size $3$.}
    \only<2>{\item[] We would like to obtain an output with the same dimensions as the input.}
    \only<3>{\item[] Hence, we apply a technique called zero padding. That is to say \enquote{pad} zeros around the input:}
    \only<4>{\item[] That always works! We just have to adjust the zeros according to the input dimensions and filter size (ie. one, two or more rows).}

  \end{itemize}

  \center
  \only<1>{\includegraphics[width=11cm]{plots/05_conv_variations/same/same0.png}}%
  \only<2>{\includegraphics[width=11cm]{plots/05_conv_variations/same/same1.png}}%
  \only<3>{\includegraphics[width=11cm]{plots/05_conv_variations/same/same2.png}}%
  \only<4>{\includegraphics[width=11cm]{plots/05_conv_variations/same/same7.png}}%

}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{

\frametitle{Padding and Network Depth}

\begin{figure}
\center
  \scalebox{0.58}{\includegraphics{plots/zeropadding.png}}
\caption{\small{\enquote{Valid} versus \enquote{same} convolution. \emph{Top} : Without padding, the width of the feature map shrinks rapidly to 1 after just three convolutional layers (filter width of 6 shown in each layer). This limits how deep the network can be made. {Bottom} : With zero padding (shown as solid circles), the feature map can remain the same size after each convolution which means the network can be made arbitrarily deep. (Goodfellow, \emph{et al.}, 2016, ch.~9)}}
\end{figure}

}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Strides}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{

\frametitle{Strides}

  \begin{itemize}

    \only<1-3>{\item Stepsize \enquote{strides} of our filter (stride = 2 shown below).}

  \end{itemize}

  \center
  \only<1>{\scalebox{0.7}{\includegraphics{plots/05_conv_variations/strides/strides0.png}}}%
  \only<2>{\scalebox{0.7}{\includegraphics{plots/05_conv_variations/strides/strides1.png}}}%
  %\only<3>{\includegraphics[width=9cm]{plots/05_conv_variations/strides/strides2.png}}%
  %\only<4>{\includegraphics[width=9cm]{plots/05_conv_variations/strides/strides3.png}}%
  \only<3>{\scalebox{0.7}{\includegraphics[width=9cm]{plots/05_conv_variations/strides/strides4.png}}}%
  
  \only<3>{\item[] In general, when there is no padding, for an input of size $i$, filter size $k$ and stride $s$, the size $o$ of the output feature map is:
    $$ o=\left\lfloor\frac{i-k}{s}\right\rfloor+ 1 $$ }

}

\frame{

\frametitle{Strides and downsampling}

\begin{figure}
\center
\includegraphics[width=.5\textwidth]{plots/stride.png}
\caption{A strided convolution is equivalent to a convolution without strides followed by downsampling (Goodfellow, \emph{et al.}, 2016, ch.~9).}
\end{figure}


}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%





\section{Pooling}

\frame{
\frametitle{Max Pooling}
  
  \center
  \only<1>{\includegraphics[width=10cm]{plots/08_pooling/pool1.png}}%
  \only<2>{\includegraphics[width=10cm]{plots/08_pooling/pool3.png}}%
  \only<3>{\includegraphics[width=10cm]{plots/08_pooling/pool6.png}}%
  %\only<4>{\includegraphics[width=10cm]{plots/08_pooling/pool8.png}}%
  
  \begin{itemize}
    \only<1>{\item We've seen how convolutions work, but there is one other operation we need to understand.}
    \only<1>{\item We want to downsample the feature map but optimally lose no information.}
    \only<2>{\item Applying the max pooling operation, we simply look for the maximum value at each spatial location.}
    \only<2>{\item That is 8 for the first location.}
    \only<2>{\item Due to the filter of size 2 we have the dimensions of the original feature map and obtain downsampling.}
    \only<3>{\item The final pooled feature map has entries 8, 6, 9 and 3.
    \only<3>{\item Max pooling brings us 2 properties: 1) dimention reduction and 2) spatial invariance.}
    \item Popular pooling functions: max and (weighted) average.}
    %\only<4>{\item Blurring the image by randomly changing pixel entries by either +1 or -1 will only marginally change activations.}
    %\only<4>{\item Next to the dimension and thus parameter reduction, pooling can increase the robustness of the net.}
  \end{itemize}
}

\frame{
\frametitle{Average Pooling}

  \center
  \only<1>{\includegraphics[width=10cm]{plots/08_pooling/avgpool0.png}}%
  \only<2>{\includegraphics[width=10cm]{plots/08_pooling/avgpool1.png}}%
  \only<3>{\includegraphics[width=10cm]{plots/08_pooling/avgpool2.png}}%
  \only<4>{\includegraphics[width=10cm]{plots/08_pooling/avgpool3.png}}%
  
  \begin{itemize}
    \only<1>{\item We've seen how max pooling worked, there are exists other pooling operation such as Avg Pooling, Fractional Pooling, LP Pooling, Wavelet Pooling, Softmax Pooling, Stochastic Pooling, Blur Pooling, Orderable Pooling, Global Average Pooling, and etc.}
    \only<1>{\item Similar to max pooling, we downsample the feature map but optimally lose no information.}
    \only<2>{\item Applying the average pooling operation, we simply look for the mean/average value at each spatial location.}
    \only<3>{\item We use all information by Sum and backpropagated to all responses. }
    \only<3>{\item It is not robust to noise. }
    \only<4>{\item The final pooled feature map has entries 3.75, 2.5, 4.25 and 1.75. }
  \end{itemize}
}


\begin{vbframe}{Comparision of Max and Average Pooling}
    \begin{itemize}
       \item Avg pooling use all information by sum but Max pooling use only highest value.
    \item In Max-pooling operation details are removed therefore it is suitable for sparse information (Image Classification) and Avg pooling is suitable for dense information (NLP) 

    \end{itemize}
    
 \begin{figure}
    \centering
    \includegraphics[width=8cm]{plots/08_pooling/comparepool.png}
    \caption{Shortcomings of Max and Average Pooling using Toy Image (source: Williams and Li, ICLR 2018)}
  \end{figure}
\end{vbframe}


%\frame{

%\frametitle{Invariance to small translation}

%\begin{figure}
%\center
%\scalebox{0.51}{\includegraphics{plots/maxpooling.png}}
%\caption{\footnotesize{Max pooling introduces invariance to small translations of the input. (\emph{Top}) A view of the middle of the output of a convolutional layer. The bottom row shows outputs of the nonlinearity. The top row shows the outputs of max pooling, with a stride of \textbf{one} pixel between pooling regions and a pooling region width of three pixels. (\emph{Bottom}) A view of the same network, after the input has been shifted to the right by one pixel. Every value in the bottom row has changed, but only half of the values in the top row have changed, because the max pooling units are sensitive only to the maximum value in the neighborhood, not its exact location (Goodfellow, \emph{et al.}, 2016, ch.~9).}}
%\end{figure}


%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Input Channel}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\frame{

\frametitle{Input Channel}

\begin{vbframe}{Input Channel}
    \begin{itemize}
       \item An image consists of the smallest indivisible segments called pixels and every pixel has a strength often known as the pixel intensity. Whenever we study a digital image, it usually comes with three color channels, i.e. the Red-Green-Blue channels, popularly known as the RGB values. 
       \item In colored images, each pixel can be represented by a vector of three numbers (each ranging from 0 to 255) for the three primary color channels: red, green, and blue.
       \item A grayscale image has a single input channel and value of each pixel represents only an amount of light; 
       \item Note a grayscale value can lie between 0 to 255, 0 signifies black and 255 signifies white. 
    \end{itemize}


 \begin{figure}
    \centering
    \includegraphics[width=4cm]{plots/05_conv_variations/channels/gray.png}
  \end{figure}

 \begin{figure}
    \centering
    \includegraphics[width=7cm]{plots/05_conv_variations/channels/RGB.jpeg}
  \end{figure}

 \begin{figure}
    \centering
    \includegraphics[width=5cm]{plots/05_conv_variations/channels/RGB-1.png}
    \caption{\tiny Image source: Computer Vision Primer: How AI Sees An Imag eKishan Maladkar's Blog)}
  \end{figure}

 \begin{figure}
    \centering
    \includegraphics[width=5cm]{plots/05_conv_variations/channels/1channel.png}
    \caption{\tiny CNNs takes grayscale image as input.}
  \end{figure}


 \begin{figure}
    \centering
    \includegraphics[width=5cm]{plots/05_conv_variations/channels/3channel.png}
    \caption{\tiny CNNs use colored images where each of the Red, Green and Blue (RGB) color spectrums serve as input. (source: Chaitanya Belwal's Blog)}
  \end{figure}

 \begin{figure}
    \centering
    \includegraphics[width=4cm]{plots/05_conv_variations/channels/cnn-net.png}
  \end{figure}

In this CNN:
    \begin{itemize}
       \item there are 3 input channel, with the size of 4x4 as an input matrices, 
       \item one 2x2 filter (also known as kernel), 
       \item a single ReLu layer,
       \item a single pooling layer (which applies the MaxPool function),
       \item and a single fully connected (FC) layer.
    \end{itemize}

    \begin{itemize}
       \item The elements of the filter matrix are equivalent to the unit weights in a standard NN and will be updated during the backpropagation phase.
       \item Assuming a stride of 2 with no padding, the size of the convolution layer is determined by the following equation:
       \item $ O = \frac{I - K + 2.P}{S} + 1$ where: 
    \begin{itemize}
       \item O: is the dimension (rows and columns) of the new(convolution) square matrix, 
       \item I: is the dimension (rows and columns) of the input square matrix,
       \item K: is the dimension (rows and columns) of the filter (kernel) square matrix, 
       \item P: is the number of pixels(cells) of padding added,
       \item S: is the stride, or the number of cells skipped each time the kernel is slided.
    \end{itemize}
    \end{itemize}

 \begin{figure}
    \centering
    \includegraphics[width=6cm]{plots/05_conv_variations/channels/cnn-net.png}
  \end{figure}

Putting these values in the equation,

\begin{align} 
O&={(4 - 2 + 2.0)\over 2} + 1\\ 
&=2 
\end{align}

\end{vbframe}



%}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%          REFERENCES          %%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{vbframe}
\frametitle{References}
\footnotesize{
\begin{thebibliography}{99}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibitem[Ian Goodfellow et al., 2016]{1} Ian Goodfellow, Yoshua Bengio and Aaron Courville (2016)
\newblock Deep Learning
\newblock \emph{\url{http://www.deeplearningbook.org/}}
\end{thebibliography}

{Extra material to have a look at:}
    \begin{itemize}
       \item Scherer, Dominik, Andreas Muller, and Sven Behnke. Evaluation of pooling operations in convolutional architectures for object recognition. at International conference on artificial neural networks. Springer, Berlin, Heidelberg, 2010.
       \item Boureau, YLan, Jean Ponce, and Yann LeCun. A theoretical analysis of feature pooling in visual recognition. Proceedings of the 27th international conference on machine learning (ICML-10). 2010.
       \item Ruderman, Avraham, et al. Pooling is neither necessary nor sufficient for appropriate deformation stability in CNNs. arXiv preprint arXiv:1804.04438 (2018).
    \end{itemize}
}
\end{vbframe}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\endlecture
\end{document}
<!DOCTYPE html>
<html>
<head>
  <meta name="databricks-html-version" content="1">
<title>MNIST for ML Beginners - Databricks</title>

<meta charset="utf-8">
<meta name="google" content="notranslate">
<meta name="robots" content="nofollow">
<meta http-equiv="Content-Language" content="en">
<meta http-equiv="Content-Type" content="text/html; charset=UTF8">
<link rel="stylesheet"
  href="https://fonts.googleapis.com/css?family=Source+Code+Pro:400,700">

<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/css/bootstrap.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/lib/jquery-ui-bundle/jquery-ui.min.css">
<link rel="stylesheet" type="text/css" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/main.css">
<link rel="stylesheet" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/css/print.css" media="print">
<link rel="icon" type="image/png" href="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/img/favicon.ico"/>
<script>window.settings = {"enableNotebookNotifications":true,"enableSshKeyUI":false,"defaultInteractivePricePerDBU":0.4,"enableOnDemandClusterType":true,"enableAutoCompleteAsYouType":[],"devTierName":"Community Edition","enableJobsPrefetching":true,"workspaceFeaturedLinks":[{"linkURI":"https://docs.databricks.com/index.html","displayName":"Documentation","icon":"question"},{"linkURI":"https://docs.databricks.com/release-notes/product/index.html","displayName":"Release Notes","icon":"code"},{"linkURI":"https://docs.databricks.com/spark/latest/training/index.html","displayName":"Training & Tutorials","icon":"graduation-cap"}],"enableClearStateFeature":false,"dbcForumURL":"http://forums.databricks.com/","enableProtoClusterInfoDeltaPublisher":true,"serverlessDefaultSparkVersion":"2.2.x-scala2.11","maxCustomTags":45,"serverlessDefaultMaxWorkers":20,"enableInstanceProfilesUIInJobs":true,"nodeInfo":{"node_types":[{"support_ssh":false,"spark_heap_memory":4800,"instance_type_id":"r3.2xlarge","spark_core_oversubscription_factor":8.0,"node_type_id":"dev-tier-node","description":"Community Optimized","support_cluster_tags":false,"container_memory_mb":6000,"node_instance_type":{"instance_type_id":"r3.2xlarge","provider":"AWS","local_disk_size_gb":160,"compute_units":26.0,"number_of_ips":14,"local_disks":1,"reserved_compute_units":3.64,"gpus":0,"memory_mb":62464,"num_cores":8,"local_disk_type":"AHCI","max_attachable_disks":0,"supported_disk_types":[{"ebs_volume_type":"GENERAL_PURPOSE_SSD"},{"ebs_volume_type":"THROUGHPUT_OPTIMIZED_HDD"}],"reserved_memory_mb":4800},"memory_mb":6144,"is_hidden":false,"category":"Community Edition","num_cores":0.88,"support_port_forwarding":false,"support_ebs_volumes":false,"is_deprecated":false}],"default_node_type_id":"dev-tier-node"},"enableDatabaseSupportClusterChoice":true,"enableClusterAcls":true,"notebookRevisionVisibilityHorizon":999999,"serverlessClusterProductName":"Serverless Pool","enableTableHandler":false,"maxEbsVolumesPerInstance":10,"isAdmin":true,"deltaProcessingBatchSize":1000,"timerUpdateQueueLength":100,"enableLargeResultDownload":true,"maxElasticDiskCapacityGB":5000,"serverlessDefaultMinWorkers":2,"zoneInfos":[{"id":"us-west-2c","isDefault":true},{"id":"us-west-2b","isDefault":false},{"id":"us-west-2a","isDefault":false}],"enableCustomSpotPricingUIByTier":false,"serverlessClustersEnabled":false,"enableEBSVolumesUIForJobs":true,"enablePublishNotebooks":true,"enableMaxConcurrentRuns":true,"enableJobAclsConfig":false,"enableFullTextSearch":false,"enableElasticSparkUI":false,"enableNewClustersCreate":true,"clusters":true,"allowRunOnPendingClusters":true,"fileStoreBase":"FileStore","enableSshKeyUIInJobs":true,"enableDetachAndAttachSubMenu":false,"configurableSparkOptionsSpec":[{"keyPattern":"spark\\.kryo(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.kryo.*","valuePatternDisplay":"*","description":"Configuration options for Kryo serialization"},{"keyPattern":"spark\\.io\\.compression\\.codec","valuePattern":"(lzf|snappy|org\\.apache\\.spark\\.io\\.LZFCompressionCodec|org\\.apache\\.spark\\.io\\.SnappyCompressionCodec)","keyPatternDisplay":"spark.io.compression.codec","valuePatternDisplay":"snappy|lzf","description":"The codec used to compress internal data such as RDD partitions, broadcast variables and shuffle outputs."},{"keyPattern":"spark\\.serializer","valuePattern":"(org\\.apache\\.spark\\.serializer\\.JavaSerializer|org\\.apache\\.spark\\.serializer\\.KryoSerializer)","keyPatternDisplay":"spark.serializer","valuePatternDisplay":"org.apache.spark.serializer.JavaSerializer|org.apache.spark.serializer.KryoSerializer","description":"Class to use for serializing objects that will be sent over the network or need to be cached in serialized form."},{"keyPattern":"spark\\.rdd\\.compress","valuePattern":"(true|false)","keyPatternDisplay":"spark.rdd.compress","valuePatternDisplay":"true|false","description":"Whether to compress serialized RDD partitions (e.g. for StorageLevel.MEMORY_ONLY_SER). Can save substantial space at the cost of some extra CPU time."},{"keyPattern":"spark\\.speculation","valuePattern":"(true|false)","keyPatternDisplay":"spark.speculation","valuePatternDisplay":"true|false","description":"Whether to use speculation (recommended off for streaming)"},{"keyPattern":"spark\\.es(\\.[^\\.]+)+","valuePattern":".*","keyPatternDisplay":"spark.es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"es(\\.([^\\.]+))+","valuePattern":".*","keyPatternDisplay":"es.*","valuePatternDisplay":"*","description":"Configuration options for ElasticSearch"},{"keyPattern":"spark\\.(storage|shuffle)\\.memoryFraction","valuePattern":"0?\\.0*([1-9])([0-9])*","keyPatternDisplay":"spark.(storage|shuffle).memoryFraction","valuePatternDisplay":"(0.0,1.0)","description":"Fraction of Java heap to use for Spark's shuffle or storage"},{"keyPattern":"spark\\.streaming\\.backpressure\\.enabled","valuePattern":"(true|false)","keyPatternDisplay":"spark.streaming.backpressure.enabled","valuePatternDisplay":"true|false","description":"Enables or disables Spark Streaming's internal backpressure mechanism (since 1.5). This enables the Spark Streaming to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process. Internally, this dynamically sets the maximum receiving rate of receivers. This rate is upper bounded by the values `spark.streaming.receiver.maxRate` and `spark.streaming.kafka.maxRatePerPartition` if they are set."},{"keyPattern":"spark\\.streaming\\.receiver\\.maxRate","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.receiver.maxRate","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which each receiver will receive data. Effectively, each stream will consume at most this number of records per second. Setting this configuration to 0 or a negative number will put no limit on the rate. See the deployment guide in the Spark Streaming programing guide for mode details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRatePerPartition","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRatePerPartition","valuePatternDisplay":"numeric","description":"Maximum rate (number of records per second) at which data will be read from each Kafka partition when using the Kafka direct stream API introduced in Spark 1.3. See the Kafka Integration guide for more details."},{"keyPattern":"spark\\.streaming\\.kafka\\.maxRetries","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.kafka.maxRetries","valuePatternDisplay":"numeric","description":"Maximum number of consecutive retries the driver will make in order to find the latest offsets on the leader of each partition (a default value of 1 means that the driver will make a maximum of 2 attempts). Only applies to the Kafka direct stream API introduced in Spark 1.3."},{"keyPattern":"spark\\.streaming\\.ui\\.retainedBatches","valuePattern":"^([0-9]{1,})$","keyPatternDisplay":"spark.streaming.ui.retainedBatches","valuePatternDisplay":"numeric","description":"How many batches the Spark Streaming UI and status APIs remember before garbage collecting."}],"enableReactNotebookComments":true,"enableAdminPasswordReset":false,"enableResetPassword":true,"maxClusterTagValueLength":255,"enableJobsSparkUpgrade":true,"perClusterAutoterminationEnabled":false,"enableNotebookCommandNumbers":true,"sparkVersions":[{"key":"1.6.3-db2-hadoop2-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-aba860a0ffce4f3471fb14aefdcb1d768ac66a53a5ad884c48745ef98aeb9d67","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.1-db5-scala2.11","displayName":"Spark 2.1.1-db5 (Scala 2.11)","packageLabel":"spark-image-08d9fc1551087e0876236f19640c4a83116b1649f15137427d21c9056656e80e","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.x-ubuntu15.10","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.4.x-ubuntu15.10","displayName":"Spark 1.4.1 (Hadoop 1)","packageLabel":"spark-image-f710650fb8aaade8e4e812368ea87c45cd8cd0b5e6894ca6c94f3354e8daa6dc","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.2.x-scala2.11","displayName":"3.0 beta (Scala 2.11)","packageLabel":"spark-image-c29cc066f8182f63337d06fbdb5d0d42656a2456da28d7a6c6eba8ce6829d145","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.1.0-db2-scala2.11","displayName":"Spark 2.1.0-db2 (Scala 2.11)","packageLabel":"spark-image-267c4490a3ab8a39acdbbd9f1d36f6decdecebf013e30dd677faff50f1d9cf8b","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.1.x-gpu-scala2.11","displayName":"Spark 2.1 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-f43ddf8ad9acfd71338f5a51345f077173d236016ad7e39ffd6f698403acd4ea","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.0-ubuntu15.10-scala2.10","displayName":"Spark 2.0.0 (Scala 2.10)","packageLabel":"spark-image-073c1b52ace74f251fae2680624a0d8d184a8b57096d1c21c5ce56c29be6a37a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db3-scala2.10","displayName":"Spark 2.0.2-db3 (Scala 2.10)","packageLabel":"spark-image-584091dedb690de20e8cf22d9e02fdcce1281edda99eedb441a418d50e28088f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db1-scala2.11","displayName":"Spark 2.1.0-db1 (Scala 2.11)","packageLabel":"spark-image-e8ad5b72cf0f899dcf2b4720c1f572ab0e87a311d6113b943b4e1d4a7edb77eb","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.1.1-db4-scala2.11","displayName":"Spark 2.1.1-db4 (Scala 2.11)","packageLabel":"spark-image-52bca0ca866e3f4243d3820a783abf3b9b3b553edf234abef14b892657ceaca9","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db2-scala2.10","displayName":"Spark 2.1.0-db2 (Scala 2.10)","packageLabel":"spark-image-a2ca4f6b58c95f78dca91b1340305ab3fe32673bd894da2fa8e1dc8a9f8d0478","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"1.6.x-ubuntu15.10-hadoop1","displayName":"Spark 1.6.x (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.2-db4-scala2.11","displayName":"Spark 2.0.2-db4 (Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.1-ubuntu15.10-hadoop1","displayName":"Spark 1.6.1 (Hadoop 1)","packageLabel":"spark-image-21d1cac181b7b8856dd1b4214a3a734f95b5289089349db9d9c926cb87d843db","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-gpu-scala2.11","displayName":"Spark 2.0 (Auto-updating, GPU, Scala 2.11 experimental)","packageLabel":"spark-image-968b89f1d0ec32e1ee4dacd04838cae25ef44370a441224177a37980d539d83a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop1","displayName":"Spark 1.6.2 (Hadoop 1)","packageLabel":"spark-image-8cea23fb9094e174bf5815d79009f4a8e383eb86cf2909cf6c6434ed8da2a16a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.6.3-db1-hadoop2-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 2, Scala 2.10)","packageLabel":"spark-image-eaa8d9b990015a14e032fb2e2e15be0b8d5af9627cd01d855df728b67969d5d9","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db2-hadoop1-scala2.10","displayName":"Spark 1.6.3-db2 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-14112ea0645bea94333a571a150819ce85573cf5541167d905b7e6588645cf3b","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.2-ubuntu15.10-hadoop2","displayName":"Spark 1.6.2 (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.6.1-ubuntu15.10-hadoop2","displayName":"Spark 1.6.1 (Hadoop 2)","packageLabel":"spark-image-4cafdf8bc6cba8edad12f441e3b3f0a8ea27da35c896bc8290e16b41fd15496a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db2-scala2.10","displayName":"Spark 2.0.2-db2 (Scala 2.10)","packageLabel":"spark-image-36d48f22cca7a907538e07df71847dd22aaf84a852c2eeea2dcefe24c681602f","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-ubuntu15.10-scala2.11","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.11, deprecated)","packageLabel":"spark-image-8e1c50d626a52eac5a6c8129e09ae206ba9890f4523775f77af4ad6d99a64c44","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-scala2.10","displayName":"Spark 2.0 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.1-db4-scala2.10","displayName":"Spark 2.1.1-db4 (Scala 2.10)","packageLabel":"spark-image-c7c0224de396cd1563addc1ae4bca6ba823780b6babe6c3729ddf73008f29ba4","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db1-scala2.11","displayName":"Spark 2.0.2-db1 (Scala 2.11)","packageLabel":"spark-image-c2d623f03dd44097493c01aa54a941fc31978ebe6d759b36c75b716b2ff6ab9c","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db4-scala2.10","displayName":"Spark 2.0.2-db4 (Scala 2.10)","packageLabel":"spark-image-859e88079f97f58d50e25163b39a1943d1eeac0b6939c5a65faba986477e311a","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.1-db5-scala2.10","displayName":"Spark 2.1.1-db5 (Scala 2.10)","packageLabel":"spark-image-74133df2c13950431298d1cab3e865c191d83ac33648a8590495c52fc644c654","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.5.x-ubuntu15.10","displayName":"Spark 1.5.2 (Hadoop 1)","packageLabel":"spark-image-c9d2a8abf41f157a4acc6d52bc721090346f6fea2de356f3a66e388f54481698","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.2.x-scala2.10","displayName":"3.0 beta (Scala 2.10)","packageLabel":"spark-image-3d735029d7732dbd8fa1c01ced355310df03f39534e7b12475ebb9e5551c6a64","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"3.0.x-scala2.11","displayName":"3.0 beta (Scala 2.11)","packageLabel":"spark-image-c29cc066f8182f63337d06fbdb5d0d42656a2456da28d7a6c6eba8ce6829d145","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.x-scala2.11","displayName":"Spark 2.0 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-7dbc7583e8271765b8a1508cb9e832768e35489bbde2c4c790bc6766aee2fd7f","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.x-scala2.10","displayName":"Spark 2.1 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-74133df2c13950431298d1cab3e865c191d83ac33648a8590495c52fc644c654","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db3-scala2.10","displayName":"Spark 2.1.0-db3 (Scala 2.10)","packageLabel":"spark-image-25a17d070af155f10c4232dcc6248e36a2eb48c24f8d4fc00f34041b86bd1626","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db2-scala2.11","displayName":"Spark 2.0.2-db2 (Scala 2.11)","packageLabel":"spark-image-4fa852ba378e97815083b96c9cada7b962a513ec23554a5fc849f7f1dd8c065a","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.3.x-ubuntu15.10","displayName":"Spark 1.3.0 (Hadoop 1)","packageLabel":"spark-image-40d2842670bc3dc178b14042501847d76171437ccf70613fa397a7a24c48b912","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.1-db1-scala2.11","displayName":"Spark 2.0.1-db1 (Scala 2.11)","packageLabel":"spark-image-10ab19f634bbfdb860446c326a9f76dc25bfa87de6403b980566279142a289ea","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.2-db3-scala2.11","displayName":"Spark 2.0.2-db3 (Scala 2.11)","packageLabel":"spark-image-7fd7aaa89d55692e429115ae7eac3b1a1dc4de705d50510995f34306b39c2397","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.3-db1-hadoop1-scala2.10","displayName":"Spark 1.6.3-db1 (Hadoop 1, Scala 2.10)","packageLabel":"spark-image-d50af1032799546b8ccbeeb76889a20c819ebc2a0e68ea20920cb30d3895d3ae","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.0.2-db1-scala2.10","displayName":"Spark 2.0.2-db1 (Scala 2.10)","packageLabel":"spark-image-654bdd6e9bad70079491987d853b4b7abf3b736fff099701501acaabe0e75c41","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.x-ubuntu15.10","displayName":"Spark 2.0 (Ubuntu 15.10, Scala 2.10, deprecated)","packageLabel":"spark-image-a659f3909d51b38d297b20532fc807ecf708cfb7440ce9b090c406ab0c1e4b7e","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.0.1-db1-scala2.10","displayName":"Spark 2.0.1-db1 (Scala 2.10)","packageLabel":"spark-image-5a13c2db3091986a4e7363006cc185c5b1108c7761ef5d0218506cf2e6643840","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.1.x-scala2.11","displayName":"Spark 2.1 (Auto-updating, Scala 2.11)","packageLabel":"spark-image-08d9fc1551087e0876236f19640c4a83116b1649f15137427d21c9056656e80e","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"2.1.0-db1-scala2.10","displayName":"Spark 2.1.0-db1 (Scala 2.10)","packageLabel":"spark-image-f0ab82a5deb7908e0d159e9af066ba05fb56e1edb35bdad41b7ad2fd62a9b546","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"3.0.x-scala2.10","displayName":"3.0 beta (Scala 2.10)","packageLabel":"spark-image-3d735029d7732dbd8fa1c01ced355310df03f39534e7b12475ebb9e5551c6a64","upgradable":true,"deprecated":false,"customerVisible":true},{"key":"1.6.0-ubuntu15.10","displayName":"Spark 1.6.0 (Hadoop 1)","packageLabel":"spark-image-10ef758029b8c7e19cd7f4fb52fff9180d75db92ca071bd94c47f3c1171a7cb5","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"1.6.x-ubuntu15.10-hadoop2","displayName":"Spark 1.6.x (Hadoop 2)","packageLabel":"spark-image-161245e66d887cd775e23286a54bab0b146143e1289f25bd1732beac454a1561","upgradable":true,"deprecated":false,"customerVisible":false},{"key":"2.0.0-ubuntu15.10-scala2.11","displayName":"Spark 2.0.0 (Scala 2.11)","packageLabel":"spark-image-b4ec141e751f201399f8358a82efee202560f7ed05e1a04a2ae8778f6324b909","upgradable":true,"deprecated":true,"customerVisible":false},{"key":"2.1.0-db3-scala2.11","displayName":"Spark 2.1.0-db3 (Scala 2.11)","packageLabel":"spark-image-ccbc6b73f158e2001fc1fb8c827bfdde425d8bd6d65cb7b3269784c28bb72c16","upgradable":true,"deprecated":false,"customerVisible":true}],"enableRestrictedClusterCreation":true,"enableFeedback":true,"enableClusterAutoScaling":false,"enableUserVisibleDefaultTags":true,"defaultNumWorkers":0,"serverContinuationTimeoutMillis":10000,"driverStderrFilePrefix":"stderr","enableNotebookRefresh":false,"accountsOwnerUrl":"https://accounts.cloud.databricks.com/registration.html#login","driverStdoutFilePrefix":"stdout","defaultNodeTypeToPricingUnitsMap":{"r3.2xlarge":2,"i3.4xlarge":6,"class-node":1,"m4.2xlarge":1.5,"r4.xlarge":1,"m4.4xlarge":3,"r4.16xlarge":16,"Standard_DS11":0.5,"p2.8xlarge":16,"m4.10xlarge":8,"r3.8xlarge":8,"r4.4xlarge":4,"dev-tier-node":1,"c3.8xlarge":4,"r3.4xlarge":4,"i2.4xlarge":6,"m4.xlarge":0.75,"r4.8xlarge":8,"r4.large":0.5,"Standard_DS12":1,"development-node":1,"i2.2xlarge":3,"g2.8xlarge":6,"i3.large":0.75,"memory-optimized":1,"m4.large":0.375,"p2.16xlarge":24,"i3.8xlarge":12,"i3.16xlarge":24,"Standard_DS12_v2":1,"Standard_DS13":2,"Standard_DS11_v2":0.5,"Standard_DS13_v2":2,"c3.2xlarge":1,"c4.2xlarge":1,"i2.xlarge":1.5,"compute-optimized":1,"c4.4xlarge":2,"i3.2xlarge":3,"c3.4xlarge":2,"g2.2xlarge":1.5,"p2.xlarge":2,"m4.16xlarge":12,"c4.8xlarge":4,"i3.xlarge":1.5,"r3.xlarge":1,"r4.2xlarge":2,"i2.8xlarge":12},"enableSparkDocsSearch":true,"sparkHistoryServerEnabled":true,"enableEBSVolumesUI":false,"sanitizeMarkdownHtml":true,"metastoreServiceRowLimit":1000000,"enableIPythonImportExport":true,"enableClusterTagsUIForJobs":true,"enableClusterTagsUI":false,"enableNotebookHistoryDiffing":true,"branch":"2.48","accountsLimit":3,"enableSparkEnvironmentVariables":true,"enableX509Authentication":false,"enableStructuredStreamingNbOptimizations":true,"enableNotebookGitBranching":true,"local":false,"enableNotebookLazyRenderWrapper":false,"enableClusterAutoScalingForJobs":false,"enableStrongPassword":false,"displayDefaultContainerMemoryGB":6,"enableNotebookCommandMode":true,"disableS3TableImport":false,"deploymentMode":"production","useSpotForWorkers":true,"enableNonPollingTableCall":true,"enableUserInviteWorkflow":true,"enableStaticNotebooks":true,"enableCssTransitions":true,"serverlessEnableElasticDisk":true,"minClusterTagKeyLength":1,"showHomepageFeaturedLinks":true,"pricingURL":"https://databricks.com/product/pricing","enableClusterAclsConfig":false,"useTempS3UrlForTableUpload":false,"notifyLastLogin":false,"enableSshKeyUIByTier":false,"defaultAutomatedPricePerDBU":0.2,"enableNotebookGitVersioning":true,"files":"files/","feedbackEmail":"feedback@databricks.com","enableDriverLogsUI":true,"enableWorkspaceAclsConfig":false,"dropzoneMaxFileSize":2047,"enableNewClustersList":false,"enableNewDashboardViews":true,"driverLog4jFilePrefix":"log4j","enableSingleSignOn":true,"enableMavenLibraries":true,"displayRowLimit":1000,"deltaProcessingAsyncEnabled":true,"enableSparkEnvironmentVariablesUI":false,"defaultSparkVersion":{"key":"2.1.x-scala2.10","displayName":"Spark 2.1 (Auto-updating, Scala 2.10)","packageLabel":"spark-image-74133df2c13950431298d1cab3e865c191d83ac33648a8590495c52fc644c654","upgradable":true,"deprecated":false,"customerVisible":true},"enableCustomSpotPricing":false,"enableMountAclsConfig":false,"defaultAutoterminationMin":180,"useDevTierHomePage":true,"enableClusterClone":true,"enableNotebookLineNumbers":true,"enablePublishHub":false,"notebookHubUrl":"http://hub.dev.databricks.com/","showSqlEndpoints":false,"enableNotebookDatasetInfoView":false,"enableClusterAclsByTier":false,"databricksDocsBaseUrl":"https://docs.databricks.com/","cloud":"AWS","disallowAddingAdmins":true,"enableSparkConfUI":true,"featureTier":"DEVELOPER_BASIC_TIER","mavenCentralSearchEndpoint":"http://search.maven.org/solrsearch/select","enableOrgSwitcherUI":true,"clustersLimit":1,"enableJdbcImport":true,"enableElasticDisk":false,"logfiles":"logfiles/","enableWebappSharding":true,"enableClusterDeltaUpdates":true,"enableSingleSignOnLogin":false,"ebsVolumeSizeLimitGB":{"GENERAL_PURPOSE_SSD":[100,4096],"THROUGHPUT_OPTIMIZED_HDD":[500,4096]},"enableMountAcls":false,"requireEmailUserName":true,"dbcFeedbackURL":"mailto:feedback@databricks.com","enableMountAclService":true,"serverlessClustersByDefault":false,"enableWorkspaceAcls":false,"maxClusterTagKeyLength":127,"gitHash":"3594d0006cfff297612107c9065dcba3695eed9c","showWorkspaceFeaturedLinks":true,"signupUrl":"https://databricks.com/try-databricks","allowFeedbackForumAccess":true,"enableImportFromUrl":true,"enableMiniClusters":true,"enableNewJobList":true,"enableNewTableUI":true,"enableDebugUI":false,"enableStreamingMetricsDashboard":true,"allowNonAdminUsers":true,"enableSingleSignOnByTier":false,"enableJobsRetryOnTimeout":true,"useStandardTierUpgradeTooltips":true,"staticNotebookResourceUrl":"https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/","enableSpotClusterType":true,"enableSparkPackages":true,"dynamicSparkVersions":true,"enableClusterTagsUIByTier":false,"enableNotebookHistoryUI":true,"enableClusterLoggingUI":true,"enableDatabaseDropdownInTableUI":true,"showDebugCounters":false,"enableInstanceProfilesUI":false,"enableFolderHtmlExport":true,"homepageFeaturedLinks":[{"linkURI":"https://docs.databricks.com/_static/notebooks/gentle-introduction-to-apache-spark.html","displayName":"Introduction to Apache Spark on Databricks","icon":"img/home/Python_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/databricks-for-data-scientists.html","displayName":"Databricks for Data Scientists","icon":"img/home/Scala_icon.svg"},{"linkURI":"https://docs.databricks.com/_static/notebooks/structured-streaming-python.html","displayName":"Introduction to Structured Streaming","icon":"img/home/Python_icon.svg"}],"enableClusterStart":false,"enableEBSVolumesUIByTier":false,"singleSignOnComingSoon":false,"upgradeURL":"https://accounts.cloud.databricks.com/registration.html#login","maxAutoterminationMinutes":10000,"autoterminateClustersByDefault":true,"notebookLoadingBackground":"#fff","sshContainerForwardedPort":2200,"enableServerAutoComplete":true,"enableStaticHtmlImport":true,"enableInstanceProfilesByTier":false,"showForgotPasswordLink":true,"defaultMemoryPerContainerMB":6000,"enablePresenceUI":true,"minAutoterminationMinutes":10,"accounts":true,"useOnDemandClustersByDefault":true,"useFramedStaticNotebooks":false,"enableNewProgressReportUI":true,"enableAutoCreateUserUI":true,"defaultCoresPerContainer":4,"showTerminationReason":true,"enableNewClustersGet":true,"showPricePerDBU":false,"showSqlProxyUI":true,"enableNotebookErrorHighlighting":true};</script>
<script>var __DATABRICKS_NOTEBOOK_MODEL = {"version":"NotebookV1","origId":15647574355612,"name":"MNIST for ML Beginners","language":"python","commands":[{"version":"CommandV1","origId":15647574355614,"guid":"20a39f3d-8bef-4d6a-8b59-02aed5a6fb90","subtype":"command","commandType":"auto","position":1.0,"command":"%md ## MNIST for ML Beginners\nThis is the MNIST for ML Beginners using TensorFlow with Databricks and TensorFrames\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1498447488942,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"7bf789f1-c715-4396-92c5-72aa17dac38b"},{"version":"CommandV1","origId":15647574355615,"guid":"89aae597-6fd7-48a2-87bc-ac6b6c45853e","subtype":"command","commandType":"auto","position":1.25,"command":"%md ## Cluster set-up\n\nTensorFrames is available as a Spark Package. To use it on your cluster, create a new library with the Source option \"Maven Coordinate\", using \"Search Spark Packages and Maven Central\" to find \"spark-deep-learning\". Then [attach the library to a cluster](https://docs.databricks.com/user-guide/libraries.html). To run this notebook, also create and attach the following libraries: \n* via PyPI: tensorflow\n* via Spark Packages: tensorframes\n\nThe latest version of TensorFrames is compatible with Spark versions 2.0 or higher and works with any instance type (CPU or GPU).","commandVersion":0,"state":"finished","results":null,"errorSummary":"<span class=\"ansired\">SyntaxError</span><span class=\"ansired\">:</span> invalid syntax","error":null,"workflows":[],"startTime":0,"submitTime":1498447488953,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"8ef8b0f0-9346-4cbb-8b7c-b442e5bad3e7"},{"version":"CommandV1","origId":15647574355616,"guid":"f2e45e44-14d6-4574-8515-aea60d306e58","subtype":"command","commandType":"auto","position":2.125,"command":"%md \n### MNIST for ML Beginners\nThese set of cells are based on the TensorFlow's [MNIST for ML Beginners](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html). \n\nThe purpose of this notebook is to use TensorFrames and Neural Networks to **automate the identification of handwritten digits** from the  [MNIST Database of Handwritten Digits](http://yann.lecun.com/exdb/mnist/) database. The source of these handwritten digits is from the National Institute of Standards and Technology (NIST) Special Database 3 (Census Bureau employees) and Special Database 1 (high-school students).\n\n![](https://www.tensorflow.org/versions/r0.9/images/MNIST.png)\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1498447488965,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"0be167c8-3982-4e1e-8d60-e42f076131ef"},{"version":"CommandV1","origId":15647574355617,"guid":"9cea69c7-6842-4734-bded-27f968f2aab1","subtype":"command","commandType":"auto","position":3.0625,"command":"%md \n### Import the Dataset\nThe MNIST dataset is comprised of:\n* `mnist.train`: 55,000 data points of training data \n* `mnist.test`: 10,000 points of test data\n* `mnist.validation`: 5,000 points of validation data","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1498447488977,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"82013864-f248-4ddb-8879-9456d1edc0eb"},{"version":"CommandV1","origId":15647574355618,"guid":"ad089083-9e2b-47ca-aa85-bcc350231721","subtype":"command","commandType":"auto","position":4.0,"command":"# Import MNIST digit images data\nfrom tensorflow.examples.tutorials.mnist import input_data\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">Extracting MNIST_data/train-images-idx3-ubyte.gz\nExtracting MNIST_data/train-labels-idx1-ubyte.gz\nExtracting MNIST_data/t10k-images-idx3-ubyte.gz\nExtracting MNIST_data/t10k-labels-idx1-ubyte.gz\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">ImportError</span>: No module named tensorflow.examples.tutorials.mnist","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ImportError</span>                               Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-1-bb70a9f18b48&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># Import MNIST digit images data</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span><span class=\"ansigreen\">from</span> tensorflow<span class=\"ansiyellow\">.</span>examples<span class=\"ansiyellow\">.</span>tutorials<span class=\"ansiyellow\">.</span>mnist <span class=\"ansigreen\">import</span> input_data<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      3</span> mnist <span class=\"ansiyellow\">=</span> input_data<span class=\"ansiyellow\">.</span>read_data_sets<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;MNIST_data/&quot;</span><span class=\"ansiyellow\">,</span> one_hot<span class=\"ansiyellow\">=</span>True<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ImportError</span>: No module named tensorflow.examples.tutorials.mnist\n</div>","workflows":[],"startTime":1498451191083,"submitTime":1498451191072,"finishTime":1498451191575,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"efdb94c6-c5fe-4564-9c2a-e6b8343dbede"},{"version":"CommandV1","origId":15647574355619,"guid":"66694c13-b755-4daf-a946-0af4adb2e9b8","subtype":"command","commandType":"auto","position":4.5,"command":"%md ### What is the image?\nWithin this dataset, this 28px x 28px 3D structure has been flattened into an array of size 784. For this tutorial, we're using a simple algorithm - `softmax regression` which does not actually make use of the 3D structure so we do not lose any information by flattening it 2D. The `.images` contains the [x,784] matrix of representing the digits while the `.labels` contain the `One-Hot Vector` representing the actual number.\n\nFor example, `mnist.train.images[25138,:]` is the array of 784 digits for the handwritten digit number `9` as indicated in `mnist.train.labels[25138,:]`.\n\n\n","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1498447488996,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"1ad91307-ca95-4975-9876-838117e5dd50"},{"version":"CommandV1","origId":15647574355620,"guid":"f57794e5-bbd1-4932-8e05-d8cedf8cc7fa","subtype":"command","commandType":"auto","position":4.75,"command":"# One-Hot Vector for xs = 25138 representing the number 9 \n#  The nth-digit will be represented as a vector which is 1 in the nth dimensions. \nmnist.train.labels[25138,:]","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">17</span><span class=\"ansired\">]: </span>array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.])\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1498447489769,"submitTime":1498447489013,"finishTime":1498447489808,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"71f6e6dc-c5a0-4593-a252-37c779f702c0"},{"version":"CommandV1","origId":15647574355621,"guid":"5ba453b7-be27-40e9-bfbb-56ebdab168d7","subtype":"command","commandType":"auto","position":5.0,"command":"# This is the extracted array for xs = 25138 from the training matrix\nmnist.train.images[25138,:]","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">18</span><span class=\"ansired\">]: </span>\narray([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.17647059,  0.60784316,\n        0.69411767,  0.72941178,  0.18431373,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.68627453,  0.97647065,  0.99607849,  0.99607849,  0.99607849,\n        0.82352948,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.01960784,  0.66274512,  0.99607849,  0.81568635,\n        0.3137255 ,  0.27058825,  0.80784321,  0.98823535,  0.18431373,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.25882354,\n        0.99607849,  0.66274512,  0.01176471,  0.        ,  0.        ,\n        0.47450984,  0.99215692,  0.5411765 ,  0.2392157 ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.03921569,  0.85098046,  0.99607849,  0.01568628,\n        0.        ,  0.        ,  0.01176471,  0.79215693,  0.99607849,\n        0.99607849,  0.73333335,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.09019608,\n        0.99607849,  0.86666673,  0.01176471,  0.        ,  0.        ,\n        0.27450982,  0.99607849,  0.98431379,  0.99607849,  0.59607846,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.09019608,  0.99607849,  0.89411771,\n        0.01176471,  0.07843138,  0.27843139,  0.7843138 ,  0.51372552,\n        0.69803923,  0.99607849,  0.38431376,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.00392157,  0.42352945,  0.99607849,  0.76078439,  0.96470594,\n        0.88235301,  0.32156864,  0.02352941,  0.80000007,  0.90980399,\n        0.03137255,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.00392157,\n        0.30980393,  0.41960788,  0.34117648,  0.05882353,  0.        ,\n        0.60000002,  0.99607849,  0.48235297,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.06666667,  0.89019614,  0.98823535,\n        0.15686275,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.16862746,  0.99607849,  0.52156866,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.62352943,  0.96862751,\n        0.16078432,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.07450981,  0.89019614,  0.66666669,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.63921571,  0.99607849,\n        0.227451  ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.87843144,  0.87843144,  0.00784314,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.41176474,  0.98823535,\n        0.48235297,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.88235301,  0.96862751,  0.14901961,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.12941177,  0.96078438,\n        0.7843138 ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.44313729,  0.99607849,  0.32941177,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.98431379,\n        0.91764712,  0.07843138,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">NameError</span>: name &apos;mnist&apos; is not defined","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-1-782412ad9327&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansired\"># This is the extracted array for xs = 25138 from the training matrix</span><span class=\"ansiyellow\"></span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>mnist<span class=\"ansiyellow\">.</span>train<span class=\"ansiyellow\">.</span>images<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">25138</span><span class=\"ansiyellow\">,</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">NameError</span>: name &apos;mnist&apos; is not defined\n</div>","workflows":[],"startTime":1498447489811,"submitTime":1498447489019,"finishTime":1498447489856,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"6ab5e7be-b597-45e8-a949-059629ca0e84"},{"version":"CommandV1","origId":15647574355622,"guid":"0a365a4a-996e-4809-a2a5-001d17303901","subtype":"command","commandType":"auto","position":5.5,"command":"%md \nBut because the output is 5 columns, its really hard to see that is the number **9**.  \n\nIf you were to take this 11,281 x 5 matrix and convert it back to a 28 x 28 matrix and add a color-scale (the higher the number, the darker the value), you will get this matrix:\n\n![](https://dennyglee.files.wordpress.com/2016/06/unflattened-digit-9-small.png)\n\nHere, you can access the [full-size version](https://dennyglee.files.wordpress.com/2016/06/unflattened-digit-9-full.png) of this image.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1498447489025,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"a9fadcd0-b9f3-4d5e-91f5-0919ac2c3484"},{"version":"CommandV1","origId":15647574355623,"guid":"c6ddceb7-62bb-441d-b7d9-daa996c0762b","subtype":"command","commandType":"auto","position":12.0,"command":"%md ## Digit Prediction\n\nFor those notebook on MNIST digit prediction, we will use the Softmax Regressions model. \nFor more information, please reference the [softmax regression](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html#softmax-regressions) analysis.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1498447489038,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"9a52e660-b86b-497c-b201-8c8cc184c017"},{"version":"CommandV1","origId":15647574355624,"guid":"ecc9e3c7-9ca6-4590-8f17-279159ffb4f4","subtype":"command","commandType":"auto","position":12.25,"command":"%md\nWe know that every image in MNIST is of a handwritten digit between zero and nine. So there are only ten possible things that a given image can be. We want to be able to look at an image and give the probabilities for it being each digit. For example, our model might look at a picture of a nine and be 80% sure it's a nine, but give a 5% chance to it being an eight (because of the top loop) and a bit of probability to all the others because it isn't 100% sure.\n\nThis is a classic case where a softmax regression is a natural, simple model. Softmax regression is a generalization of logistic regression to the case where we want to handle multiple classes. If you want to assign probabilities to an object being one of several different things, softmax is the thing to do, because softmax gives us a list of values between 0 and 1 that add up to 1. Even later on, when we train more sophisticated models, the final step will be a layer of softmax.  \n\nA softmax regression has two steps: first we add up the evidence of our input being in certain classes, and then we convert that evidence into probabilities.\n\nTo tally up the evidence that a given image is in a particular class, we do a weighted sum of the pixel intensities. The weight is negative if that pixel having a high intensity is evidence against the image being in that class, and positive if it is evidence in favor.\n![](https://raw.githubusercontent.com/joyq2016/demo/master/softmaxtext.png)\n\nBut it's often more helpful to think of softmax the first way: exponentiating its inputs and then normalizing them. The exponentiation means that one more unit of evidence increases the weight given to any hypothesis multiplicatively. And conversely, having one less unit of evidence means that a hypothesis gets a fraction of its earlier weight. No hypothesis ever has zero or negative weight. Softmax then normalizes these weights, so that they add up to one, forming a valid probability distribution.\n\nSource: https://www.tensorflow.org/get_started/mnist/beginners\n\n####Let's look at an example below:\n\n\n\n\n\n![](https://raw.githubusercontent.com/joyq2016/demo/master/softmax.png)\n\nSource: https://cs231n.github.io/linear-classify/\n\n\nMore information about how Softmax Regression works, good references include:\n- http://www.kdnuggets.com/2016/07/softmax-regression-related-logistic-regression.html\n- https://www.tensorflow.org/get_started/mnist/beginners\n- Deep dive: http://neuralnetworksanddeeplearning.com/chap3.html#softmax","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":0,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"fc34160f-6de2-4186-8174-5f95892d11a8"},{"version":"CommandV1","origId":15647574355625,"guid":"025d4413-3113-44ca-92b7-45cb778c5a65","subtype":"command","commandType":"auto","position":12.5,"command":"%md #### Implementing Softmax Regressions model","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1498447489051,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"61e51a13-5525-41ec-9e32-ce47cf23df23"},{"version":"CommandV1","origId":15647574355626,"guid":"64e52483-8439-46b1-9436-8e632d08b765","subtype":"command","commandType":"auto","position":13.0,"command":"# Import TensorFlow\nimport tensorflow as tf\n\n# Create `x` placeholder\n#   Place any any number of MNIST images, each flattened into a 784-dimensional vector\n#   This is represented  as a 2-D tensor of floating-point numbers, with a shape [None, 784]\nx = tf.placeholder(tf.float32, [None, 784])\n\n# Set the weights (`W`) and biases (`b`) for our model\n#   Use a Variable - a modificable tensor that lives in TensorFlow's graph of interacting operations\n#   We initalize them them with `zeros`\nW = tf.Variable(tf.zeros([784, 10]))\nb = tf.Variable(tf.zeros([10]))\n\n# Implement Softmax Regressions model\ny = tf.nn.softmax(tf.matmul(x, W) + b)","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":null,"error":null,"workflows":[],"startTime":1498452100707,"submitTime":1498452100695,"finishTime":1498452100748,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"d56de0e1-0ea0-49c9-b474-5e5216cd199e"},{"version":"CommandV1","origId":15647574355627,"guid":"805e72a8-dc89-4ad5-adb5-63acf48007eb","subtype":"command","commandType":"auto","position":14.0,"command":"%md #### Training the model\nUse the `cross-entropy` cost function to define what it means for the model to be good.  For more information, please reference [MNIST for Beginners > Training](https://www.tensorflow.org/versions/r0.9/tutorials/mnist/beginners/index.html#training)","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1498452100777,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"295145d0-48f2-46db-94ae-a04e8fd565a2"},{"version":"CommandV1","origId":15647574355628,"guid":"b0b50710-069e-4c58-bbb8-0977e7516f77","subtype":"command","commandType":"auto","position":15.0,"command":"# Create `y_` placeholder Variable to input correct answers\ny_ = tf.placeholder(tf.float32, [None, 10])\n\n# Implement the `cross-entopy` cost function\n#cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y))\n\n# Traing using back-propagation (gradient descent optimizer)\ntrain_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n\n# Launch the model\nsess = tf.InteractiveSession()\n\n# Initialize the variables\ntf.global_variables_initializer().run()\n\n# Let's train -- running the training step 1000 times\n#for _ in range(1000):\n#  batch_xs, batch_ys = mnist.train.next_batch(100)\n#  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys}) \nfor _ in range(1000):\n  batch = mnist.train.next_batch(100)\n  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n  \n#for _ in range(1000):\n#  batch = mnist.train.next_batch(100)\n#  train_step.run(feed_dict={x: batch[0], y_: batch[1]})","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\"></div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"<span class=\"ansired\">ValueError</span>: Cannot execute operation using &#96;run()&#96;: No default session is registered. Use &#96;with sess.as_default():&#96; or pass an explicit session to &#96;run(session=sess)&#96;","error":"<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">ValueError</span>                                Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;ipython-input-6-6054b33a2e95&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">     22</span> <span class=\"ansigreen\">for</span> _ <span class=\"ansigreen\">in</span> range<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">1000</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">     23</span>   batch <span class=\"ansiyellow\">=</span> mnist<span class=\"ansiyellow\">.</span>train<span class=\"ansiyellow\">.</span>next_batch<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">100</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">---&gt; 24</span><span class=\"ansiyellow\">   </span>train_step<span class=\"ansiyellow\">.</span>run<span class=\"ansiyellow\">(</span>feed_dict<span class=\"ansiyellow\">=</span><span class=\"ansiyellow\">{</span>x<span class=\"ansiyellow\">:</span> batch<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">0</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">,</span> y_<span class=\"ansiyellow\">:</span> batch<span class=\"ansiyellow\">[</span><span class=\"ansicyan\">1</span><span class=\"ansiyellow\">]</span><span class=\"ansiyellow\">}</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc</span> in <span class=\"ansicyan\">run</span><span class=\"ansiblue\">(self, feed_dict, session)</span>\n<span class=\"ansigreen\">   1704</span>         none<span class=\"ansiyellow\">,</span> the default session will be used<span class=\"ansiyellow\">.</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1705</span>     &quot;&quot;&quot;\n<span class=\"ansigreen\">-&gt; 1706</span><span class=\"ansiyellow\">     </span>_run_using_default_session<span class=\"ansiyellow\">(</span>self<span class=\"ansiyellow\">,</span> feed_dict<span class=\"ansiyellow\">,</span> self<span class=\"ansiyellow\">.</span>graph<span class=\"ansiyellow\">,</span> session<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1707</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1708</span> <span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/python/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc</span> in <span class=\"ansicyan\">_run_using_default_session</span><span class=\"ansiblue\">(operation, feed_dict, graph, session)</span>\n<span class=\"ansigreen\">   3947</span>     session <span class=\"ansiyellow\">=</span> get_default_session<span class=\"ansiyellow\">(</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   3948</span>     <span class=\"ansigreen\">if</span> session <span class=\"ansigreen\">is</span> None<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">-&gt; 3949</span><span class=\"ansiyellow\">       raise ValueError(&quot;Cannot execute operation using &#96;run()&#96;: No default &quot;\n</span><span class=\"ansigreen\">   3950</span>                        <span class=\"ansiblue\">&quot;session is registered. Use &#96;with &quot;</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   3951</span>                        <span class=\"ansiblue\">&quot;sess.as_default():&#96; or pass an explicit session to &quot;</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">ValueError</span>: Cannot execute operation using &#96;run()&#96;: No default session is registered. Use &#96;with sess.as_default():&#96; or pass an explicit session to &#96;run(session=sess)&#96;</div>","workflows":[],"startTime":1498452100865,"submitTime":1498452100852,"finishTime":1498452102275,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"056dae37-c5f2-4aa9-8cda-8c70ed45d30d"},{"version":"CommandV1","origId":15647574355629,"guid":"8bcc50fd-5eef-4a2b-b1bf-cd049c74d5d4","subtype":"command","commandType":"auto","position":16.0,"command":"%md #### Evaluating the model\nTo evaluate the model we use the ```tf.argmax(...)``` method; the ```tf.argmax(y,1)``` will return the index from the predicted vector ```y```. We do the same for the target ```y_```. Using the ```tf.equal(...)``` method we then compare the two to see if we got a correct prediction. \n\nThe above will return a list of booleans in a form of ```[True, False, True, True]```. We then cast it to float to get (for this example): ```[1,0,1,1]```. The ```tf.reduce_mean(...)``` method takes the list of floats and returns an average. Finally, we feed the TensorFlow engine with the testing data: by calling the ```.eval(...)``` method we specify our input testing images from the ```mnist.test.images``` set, and the labels ```y_```: the ```mnist.test.labels```. \n\nOnly upon calling the ```.eval(...)``` TensorFlow will loop through all the testing images, check if predicted correctly, and return an average accuracy.","commandVersion":0,"state":"finished","results":null,"errorSummary":null,"error":null,"workflows":[],"startTime":0,"submitTime":1498452100920,"finishTime":0,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"733e9b99-b870-453c-b6c0-b2616a1027d5"},{"version":"CommandV1","origId":15647574355630,"guid":"b9420cf0-0908-4e1e-b2d5-ec936ccc85af","subtype":"command","commandType":"auto","position":19.0,"command":"correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\nprint(accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n#print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))","commandVersion":0,"state":"finished","results":{"type":"html","data":"<div class=\"ansiout\">0.9071\n</div>","arguments":{},"addedWidgets":{},"removedWidgets":[],"datasetInfos":[]},"errorSummary":"Command skipped","error":null,"workflows":[],"startTime":1498452102279,"submitTime":1498452100960,"finishTime":1498452102350,"collapsed":false,"bindings":{},"inputWidgets":{},"displayType":"table","width":"auto","height":"auto","xColumns":null,"yColumns":null,"pivotColumns":null,"pivotAggregation":null,"customPlotOptions":{},"commentThread":[],"commentsVisible":false,"parentHierarchy":[],"diffInserts":[],"diffDeletes":[],"globalVars":{},"latestUser":"a user","commandTitle":"","showCommandTitle":false,"hideCommandCode":false,"hideCommandResult":false,"iPythonMetadata":null,"streamStates":{},"nuid":"bb902dce-d237-45ea-b577-133f5464222c"}],"dashboards":[],"guid":"f0659d8f-6a64-46be-910a-c38540997b03","globalVars":{},"iPythonMetadata":null,"inputWidgets":{}};</script>
<script
 src="https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js"
 onerror="window.mainJsLoadError = true;"></script>
</head>
<body>
  <script>
if (window.mainJsLoadError) {
  var u = 'https://databricks-prod-cloudfront.cloud.databricks.com/static/e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855/js/notebook-main.js';
  var b = document.getElementsByTagName('body')[0];
  var c = document.createElement('div');
  c.innerHTML = ('<h1>Network Error</h1>' +
    '<p><b>Please check your network connection and try again.</b></p>' +
    '<p>Could not load a required resource: ' + u + '</p>');
  c.style.margin = '30px';
  c.style.padding = '20px 50px';
  c.style.backgroundColor = '#f5f5f5';
  c.style.borderRadius = '5px';
  b.appendChild(c);
}
</script>
</body>
</html>

<<setup-child, include = FALSE>>=
library(knitr)
set_parent("../../style/preamble_ueb.Rnw")
@


\kopf{1}


\aufgabe{
 Go to \url{https://www.kaggle.com/t/f8eadb8074fb4921805f8d756056fe10} where you'll find a small
 deep learning competition for our lecture.
 The data looks similar to the MNIST example you've seen in the lecture.
 Train a deep neural network on the training data \texttt{train.csv} and predict \texttt{test.csv}.
 Upload a csv file with the predictions and ids to get your score and place on the leaderboard.

 \textbf{Good Luck!}
}

\dlz

\aufgabe{
  Implement the perceptron as introduced in the lecture.
  Use the delta-update rule for training. Train the perceptron on the \texttt{Sonar} dataset from the \texttt{mlbench} package.

  What does happen if you train your perceptron on the \texttt{XOR} example?

}


\dlz


\aufgabe{
  Show the derivative of the cross entropy error function (slide 25)
  with respect to the activation $z_k$ for an output unit having a logistic sigmoid activation function satisfies

  \[
  \frac{\partial L}{\partial z_k} = y_k - f(x)_k.
  \]
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89bf85cf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 9\n",
    "\n",
    "Hüseyin Anil Gündüz\n",
    "\n",
    "In the first part of the lab, we will analytically derive the backpropagation equations for a simple RNN.\n",
    "Then, in the second part, we will implement forward and backward propagation functions for a simple RNN-model,\n",
    "and train to  predict the future temperature based on past weather metrics.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4374da77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:53.648392Z",
     "iopub.status.busy": "2022-01-05T16:44:53.647119Z",
     "iopub.status.idle": "2022-01-05T16:44:54.882494Z",
     "shell.execute_reply": "2022-01-05T16:44:54.881982Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import urllib.request\n",
    "from operator import itemgetter\n",
    "from typing import Tuple, Dict\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats('png', 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eab552",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 1\n",
    "In this part, we derive the backpropagation equations for a simple RNN from forward propagation equations. For simplicity, we will focus on a single input sequence $\\textbf{x}^{[1]},\\ldots,\\textbf{x}^{[\\tau]}$. The forward pass in a RNN with hyperbolic tangent activation at time $t$ is given by:\n",
    "\\begin{align}\n",
    "\\textbf{h}^{[t]} &= \\tanh {(\\textbf{W} \\textbf{h}^{[t-1]} + \\textbf{U} \\textbf{x}^{[t]} + \\textbf{b})} \\\\\n",
    "\\textbf{y}^{[t]} &= \\textbf{V}\\textbf{h}^{[t]}+\\textbf{c}\n",
    "\\end{align}\n",
    "where the parameters are the bias vectors $\\textbf{b}$ and $\\textbf{c}$ along with the weight matrices $\\textbf{U}$,$\\textbf{V}$ and $\\textbf{W}$, respectively, for input-to-hidden, hidden-to-output and hidden-to-hidden connections. As we will use RNN for a regression problem in the of the exercise, we do not use an activation function in order to compute the output $\\textbf{y}^{[t]}$ (at time $t$).\n",
    "\n",
    "The loss is defined as:\n",
    "\\begin{equation}\n",
    "\\mathcal{L}=\\sum_{t=1}^{\\tau}\\mathcal{L}\\left(\\textbf{y}^{[t]}, \\hat{\\textbf{y}}^{[t]}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Show that:\n",
    "\\begin{align}\n",
    "\\nabla_{\\textbf{h} ^{[\\tau]}} \\mathcal{L}\n",
    "&= \\textbf{V}^{T} (\\nabla_{\\textbf{y} ^{[\\tau]}}\\mathcal{L}) \\\\\n",
    "\\nabla_{\\textbf{h} ^{[t]}}  \\mathcal{L}\n",
    "&= \\textbf{W}^{T} \\text{diag}\\bigg(1-\\big(\\textbf{h}^{[t+1]}\\big)^{^2} \\bigg)(\\nabla_{\\textbf{h}{^{[t+1]}}}{{L}}) + \\textbf{V}^{T} (\\nabla_{\\textbf{y} ^{[t]}}\\mathcal{L}) \\\\\n",
    "\\nabla_\\textbf{c}  \\mathcal{L}\n",
    "&= \\sum_{t=1}^{\\tau}\\nabla_{\\textbf{y}{^{[t]}}}{{\\mathcal{L}}} \\\\\n",
    "\\nabla_\\textbf{b}  \\mathcal{L}\n",
    "&= \\sum_{t=1}^{\\tau} \\text{diag}\\bigg(1-\\big(\\textbf{h}^{[t]}\\big)^{2} \\bigg) \\nabla_{\\textbf{h}^{[t]}}\\mathcal{L} \\\\\n",
    "\\nabla_\\textbf{V}  \\mathcal{L}\n",
    "&=\\sum_{t=1}^{\\tau}(\\nabla_{\\textbf{y}{^{[t]}}}{\\mathcal{L}})  \\textbf{h}^{{[t]}^{T}} \\\\\n",
    "\\nabla_\\textbf{W}  \\mathcal{L}\n",
    "&=\\sum_{t=1}^{\\tau} \\text{diag}\\bigg(1-\\big(\\textbf{h}^{[t]}\\big)^{2} \\bigg)\\ (\\nabla_{\\textbf{h}{^{[t]}}}{{\\mathcal{L}}}) \\textbf{h}^{{[t-1]}^{T}} \\\\\n",
    "\\nabla_\\textbf{U}  \\mathcal{L}\n",
    "&= \\sum_{t=1}^{\\tau} \\text{diag}\\bigg(1-\\big(\\textbf{h}^{[t]}\\big)^{2} \\bigg)(\\nabla_{\\textbf{h}{^{[t]}}}{{\\mathcal{L}}}) \\textbf{x}^{{[t]}^{T}}\n",
    "\\end{align}\n",
    "\n",
    "Hint 1 (chain rule for vector calculus): given a vector $\\textbf{x}\\in\\mathbb{R}^n$ and two functions $f:\\mathbb{R}^n\\rightarrow\\mathbb{R}^m$ and $g:\\mathbb{R}^m\\rightarrow\\mathbb{R}$, call the outputs $\\textbf{y}=f(\\textbf{x})$ and $z=g(\\textbf{y})=g(f(\\textbf{x}))$, then the following holds:\n",
    "\\begin{equation}\n",
    "\\nabla_{\\textbf{x}} z\n",
    "=\n",
    "\\nabla_{\\textbf{x}}\\textbf{y}\n",
    "\\cdot\n",
    "\\nabla_{\\textbf{y}} z\n",
    "\\end{equation}\n",
    "where $\\nabla_{\\textbf{y}} z\\in\\mathbb{R}^m$ and $\\nabla_{\\textbf{x}}\\textbf{y}\\in\\mathbb{R}^n\\times\\mathbb{R}^m$.\n",
    "\n",
    "Hint 2: draw a computational graph representing the computation performed by the RNN unrolled over time, then use this graph to compute the gradients: multiply gradients via the chain rule when traversing edges, and sum the gradients obtained along each path from the loss to the item you are differentiating against.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8749b78",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## Exercise 2\n",
    "In the second exercise, we are going to be estimating only the temperature value of the next hour from the given past 24 hours of weather-related information.\n",
    "Thus we will not be computing any intermediate output from the RNN and only one scalar value at the final step. Additionally, we will use mean square error as a loss function.\n",
    "\n",
    "Given this information, show that:\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla_{\\textbf{h} ^{[\\tau]}} \\mathcal{L}\n",
    "&=2(\\hat y-y) \\textbf{V}^{T} \\\\\n",
    "\\nabla_{\\textbf{h} ^{[t]}}\\mathcal{L}\n",
    "&= \\textbf{W}^{T} \\cdot \\text{diag}\\bigg(1-{\\textbf{h}^{[t+1]}}^{2} \\bigg)\\cdot\\nabla_{\\textbf{h}{^{[t+1]}}}{\\mathcal{L}} \\\\\n",
    "\\nabla_{\\textbf{c}} \\mathcal{L}\n",
    "&= 2(\\hat y-y) \\\\\n",
    "\\nabla_\\textbf{V} \\mathcal{L}\n",
    "&= 2(\\hat y-y) \\textbf{h}^{{[\\tau]}^{T}}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7e5fe8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 3\n",
    "In this exercise, we will implement forward and backward propagation steps of the simple RNN and train it on a real data.\n",
    "We will stick to the notation the we used in the first part of the exercise.\n",
    "\n",
    "### Prepare the data\n",
    "In this exercise we will develop a model that estimates the temperature of the following hour from different weather parameters in the last 24 hours.\n",
    "The dataset includes the features described in the table below.\n",
    "\n",
    "We download the dataset from github and print out the first rows and the dimensions of file.\n",
    "We will use DEWP, TEMP, PRES, cbwd, Iws, Is, Ir features as input and not the pollution, since pm2.5 contains some NA values we do not want to deal with.\n",
    "\n",
    "![](lab9table1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313a3ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:54.887760Z",
     "iopub.status.busy": "2022-01-05T16:44:54.887299Z",
     "iopub.status.idle": "2022-01-05T16:44:55.318660Z",
     "shell.execute_reply": "2022-01-05T16:44:55.318217Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pollution.csv'\n",
    "response = urllib.request.urlopen(url)\n",
    "lines = [l.decode('utf-8') for l in response.readlines()]\n",
    "data_list = [row for row in csv.reader(lines)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c115519",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The first row contains the header/column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19ba68ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.322938Z",
     "iopub.status.busy": "2022-01-05T16:44:55.322449Z",
     "iopub.status.idle": "2022-01-05T16:44:55.324444Z",
     "shell.execute_reply": "2022-01-05T16:44:55.324825Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', 'year', 'month', 'day', 'hour', 'pm2.5', 'DEWP', 'TEMP', 'PRES', 'cbwd', 'Iws', 'Is', 'Ir']\n"
     ]
    }
   ],
   "source": [
    "print(data_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b42a7",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As stated before, we will use DEWP, TEMP, PRES, cbwd, Iws, Is, Ir as features. Thus, we select the correct columns and create a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d16d7e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.429132Z",
     "iopub.status.busy": "2022-01-05T16:44:55.332290Z",
     "iopub.status.idle": "2022-01-05T16:44:55.510737Z",
     "shell.execute_reply": "2022-01-05T16:44:55.510284Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 42984 columns and 6 features.\n",
      "tensor([[ -21.0000,  -11.0000, 1021.0000,    1.7900,    0.0000,    0.0000],\n",
      "        [ -21.0000,  -12.0000, 1020.0000,    4.9200,    0.0000,    0.0000],\n",
      "        [ -21.0000,  -11.0000, 1019.0000,    6.7100,    0.0000,    0.0000],\n",
      "        [ -21.0000,  -14.0000, 1019.0000,    9.8400,    0.0000,    0.0000],\n",
      "        [ -20.0000,  -12.0000, 1018.0000,   12.9700,    0.0000,    0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Let's remove the header now.\n",
    "# We will also only handle the first 43000 entries to comply with the original R exercise ;)\n",
    "data_list = data_list[1:43001]\n",
    "\n",
    "# We then remove the last day, because it is missing observations\n",
    "num_rows = len(data_list) - len(data_list) % 24\n",
    "data_list = data_list[:num_rows]\n",
    "\n",
    "filtered_data_list = []\n",
    "for row in data_list:\n",
    "    selection = itemgetter(6, 7, 8, 10, 11, 12)(row)\n",
    "    selection = [float(elem) for elem in selection]\n",
    "    filtered_data_list.append(selection)\n",
    "\n",
    "dataset = torch.tensor(filtered_data_list, dtype=torch.float)\n",
    "print('The dataset has {} columns and {} features.'.format(*dataset.shape))\n",
    "print(dataset[:5])\n",
    "\n",
    "# Let's delete the old stuff. We don't need it anymore\n",
    "del data_list, filtered_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb723340",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The data is already sorted by time, from oldest to newest observation. We then create a test set using the last 20% of days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee66feba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.514587Z",
     "iopub.status.busy": "2022-01-05T16:44:55.514117Z",
     "iopub.status.idle": "2022-01-05T16:44:55.527775Z",
     "shell.execute_reply": "2022-01-05T16:44:55.528175Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_train_samples = (\n",
    "# TODO: Compute the number of train samples if 20% of the days are separated for testing\n",
    ")\n",
    "\n",
    "data_train = dataset[:num_train_samples]\n",
    "data_test = dataset[num_train_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507d9cbc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now standardize the data to have zero mean and unit standard deviation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cad8f274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.536027Z",
     "iopub.status.busy": "2022-01-05T16:44:55.532272Z",
     "iopub.status.idle": "2022-01-05T16:44:55.544032Z",
     "shell.execute_reply": "2022-01-05T16:44:55.544383Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "means = (\n",
    "# TODO: Compute the mean of each column of the dataset\n",
    ")\n",
    "\n",
    "stds = (\n",
    "# TODO: Compute the standard deviation of each column of the dataset\n",
    ")\n",
    "\n",
    "data_train = (\n",
    "# TODO: Standardize the training data\n",
    ")\n",
    "\n",
    "data_test = (\n",
    "# TODO: Standardize the training data\n",
    ")\n",
    "\n",
    "# Check if standardization worked\n",
    "print('This should be close to zero:', torch.mean(data_train, dim=0))\n",
    "print('This should be close to one:', torch.std(data_train, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c79f9c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now create a function to return a single random sequence of 24 contiguous observations along with the temperature to predict:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea759c6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.554291Z",
     "iopub.status.busy": "2022-01-05T16:44:55.552092Z",
     "iopub.status.idle": "2022-01-05T16:44:55.560731Z",
     "shell.execute_reply": "2022-01-05T16:44:55.560273Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_random_day(data: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"Get 24 random contiguous hours from the dataset.\"\"\"\n",
    "    start_idx = (\n",
    "# TODO: Sample a valid random index\n",
    "    )\n",
    "\n",
    "    x = data[start_idx: start_idx + 24]\n",
    "    y = data[start_idx + 24, 1]\n",
    "    # The magic number 1 above corresponds to the second column in the features, which is temperature.\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# Check for correct shape\n",
    "x, y = get_random_day(data_train)\n",
    "assert x.shape == (24, 6) and y.shape == (1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda5f10",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### RNN implementation\n",
    "Let's define our own RNN module and initialize U, W, V, b and c weights randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ae4851",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.571592Z",
     "iopub.status.busy": "2022-01-05T16:44:55.571064Z",
     "iopub.status.idle": "2022-01-05T16:44:55.577266Z",
     "shell.execute_reply": "2022-01-05T16:44:55.577638Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class RNN:\n",
    "    def __init__(self, hidden_state_size: int = 10, num_features: int = 6) -> None:\n",
    "        self.hidden_state_size = hidden_state_size\n",
    "        self.num_features = num_features\n",
    "\n",
    "        init_distribution = Normal(0, 0.001)\n",
    "\n",
    "        self.u = init_distribution.sample((hidden_state_size, num_features))\n",
    "        self.w = init_distribution.sample((hidden_state_size, hidden_state_size))\n",
    "        self.v = init_distribution.sample((hidden_state_size,))\n",
    "        self.b = torch.zeros(hidden_state_size)\n",
    "        self.c = torch.zeros(1)\n",
    "\n",
    "    # We will now define a function for the forward propagation,\n",
    "    # which will return the prediction of the network as well as all intermediate hidden states:\n",
    "    def forward(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"Pass a timeseries through the RNN.\"\"\"\n",
    "        h_dims = (\n",
    "# TODO: Compute the shape of the hidden state matrix\n",
    "# Hint: Add an additional state for the initialization\n",
    "        )\n",
    "        h = torch.zeros(h_dims)\n",
    "\n",
    "# TODO: Compute and save all hidden states\n",
    "\n",
    "        y = (\n",
    "# TODO: Compute the output of the RNN\n",
    "        )\n",
    "        return h[1:], y\n",
    "\n",
    "    def __call__(self, x: Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        return self.forward(x)\n",
    "\n",
    "    # We now define functions computing the gradient for each parameter of the network separately, starting from the hidden states:\n",
    "\n",
    "    def _compute_grad_h(self, y_true: Tensor, y_pred: Tensor, hidden: Tensor) -> Tensor:\n",
    "        \"\"\"Compute the gradient w.r.t. h\"\"\"\n",
    "        grad_h = (\n",
    "# TODO: Initialize the hidden gradient matrix with zeros\n",
    "        )\n",
    "\n",
    "# TODO: Compute the gradient of the last hidden state\n",
    "\n",
    "        for i in reversed(range(len(hidden) - 1)):\n",
    "# TODO: Compute the gradient of the i-th hidden state\n",
    "\n",
    "        return grad_h\n",
    "\n",
    "    def _compute_grad_c(self, y_true: Tensor, y_pred: Tensor) -> Tensor:\n",
    "        \"\"\"Compute the gradient w.r.t. c. (The bias of the output layer)\"\"\"\n",
    "# TODO: Compute the gradient w.r.t. c and return it\n",
    "\n",
    "    def _compute_grad_b(self, hidden: Tensor, grad_h: Tensor) -> Tensor:\n",
    "        \"\"\"Compute the gradient w.r.t. b. (The bias of the recurrent layer)\"\"\"\n",
    "        grad_b = torch.zeros_like(self.b)\n",
    "# TODO: Compute the gradient w.r.t. b\n",
    "        return grad_b\n",
    "\n",
    "    def _compute_grad_v(self, y_true: Tensor, y_pred: Tensor, hidden: Tensor) -> Tensor:\n",
    "        \"\"\"Compute the gradient w.r.t. v. (The bias of the output weights)\"\"\"\n",
    "# TODO: Compute the gradient w.r.t. v and return it\n",
    "\n",
    "    def _compute_grad_w(self, hidden: Tensor, grad_h: Tensor) -> Tensor:\n",
    "        \"\"\"Compute the gradient w.r.t. w. (The hidden-to-hidden weights)\"\"\"\n",
    "        grad_w = torch.zeros_like(self.w)\n",
    "# TODO: Compute the gradient w.r.t. w\n",
    "        return grad_w\n",
    "\n",
    "    def _compute_grad_u(self, hidden: Tensor, grad_h: Tensor, x: Tensor) -> Tensor:\n",
    "        \"\"\"Compute the gradient w.r.t. u. (The input-to-hidden weights)\"\"\"\n",
    "        grad_w = torch.zeros_like(self.u)\n",
    "# TODO: Compute the gradient w.r.t. u\n",
    "        return grad_w\n",
    "\n",
    "    def get_gradients(self, x: Tensor, y_true: Tensor, y_pred: Tensor, hidden: Tensor) -> Dict:\n",
    "        \"\"\"Obtain all gradients for a prediction.\"\"\"\n",
    "        grad_h = self._compute_grad_h(y_true, y_pred, hidden)\n",
    "        return {\n",
    "            \"grad_c\": self._compute_grad_c(y_true, y_pred),\n",
    "            \"grad_b\": self._compute_grad_b(hidden, grad_h),\n",
    "            \"grad_v\": self._compute_grad_v(y_true, y_pred, hidden),\n",
    "            \"grad_w\": self._compute_grad_w(hidden, grad_h),\n",
    "            \"grad_u\": self._compute_grad_u(hidden, grad_h, x)\n",
    "        }\n",
    "\n",
    "# Compute some dummy values to see if your implementation works without throwing errors.\n",
    "# (And in practice please use unit tests!)\n",
    "rnn = RNN()\n",
    "x, y = get_random_day(data_train)\n",
    "h, y_hat = rnn(x)\n",
    "grad_h = rnn._compute_grad_h(y, y_hat, h)\n",
    "grad_c = rnn._compute_grad_c(y, y_hat)\n",
    "grad_b = rnn._compute_grad_b(h, grad_h)\n",
    "grad_v = rnn._compute_grad_v(y, y_hat, h)\n",
    "grad_w = rnn._compute_grad_w(h, grad_h)\n",
    "grad_u = rnn._compute_grad_u(h, grad_h, x)\n",
    "\n",
    "# Check if your implementation returns the correct shapes\n",
    "assert h.shape == (24, 10)\n",
    "assert y.shape == (1, )\n",
    "assert grad_h.shape == (24, 10)\n",
    "assert grad_c.shape == (1, )\n",
    "assert grad_b.shape == (10, )\n",
    "assert grad_v.shape == (10, )\n",
    "assert grad_w.shape == (10, 10)\n",
    "assert grad_u.shape == (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa618d1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we need a loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b748b66a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.586453Z",
     "iopub.status.busy": "2022-01-05T16:44:55.585963Z",
     "iopub.status.idle": "2022-01-05T16:44:55.593581Z",
     "shell.execute_reply": "2022-01-05T16:44:55.593115Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def mse_loss_func(y_true: Tensor, y_pred: Tensor) -> Tensor:\n",
    "# TODO: Compute the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986e0787",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Training step\n",
    "\n",
    "Let us now put all the functions we defined above together to execute a single training step on a randomly sampled minibatch of data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbeb492d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.602593Z",
     "iopub.status.busy": "2022-01-05T16:44:55.601933Z",
     "iopub.status.idle": "2022-01-05T16:44:55.610326Z",
     "shell.execute_reply": "2022-01-05T16:44:55.609832Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def do_training_step(rnn: RNN, data_train: Tensor, batch_size: int, lr: float) -> float:\n",
    "\n",
    "    total_loss = 0\n",
    "    grad_c_list = []\n",
    "    grad_b_list = []\n",
    "    grad_v_list = []\n",
    "    grad_w_list = []\n",
    "    grad_u_list = []\n",
    "\n",
    "    for _ in range(batch_size):\n",
    "# TODO: Perform a forward pass and compute the loss\n",
    "\n",
    "        total_loss = float(loss)\n",
    "\n",
    "# TODO: Obtain and accumulate all gradients in the above lists\n",
    "\n",
    "# TODO: Update the weights via the accumulated gradients\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee21b96",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Training loop\n",
    "We now have all components needed to train our network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50ea2725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.619731Z",
     "iopub.status.busy": "2022-01-05T16:44:55.619241Z",
     "iopub.status.idle": "2022-01-05T16:44:55.627063Z",
     "shell.execute_reply": "2022-01-05T16:44:55.626680Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train_rnn(data_train: Tensor, num_steps) -> Tuple[RNN, list]:\n",
    "    losses = []\n",
    "    rnn = RNN()\n",
    "\n",
    "    for _ in range(num_steps):\n",
    "# TODO: Perform a training step\n",
    "\n",
    "        losses.append(loss)\n",
    "\n",
    "    return rnn, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "035f96f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.635114Z",
     "iopub.status.busy": "2022-01-05T16:44:55.631046Z",
     "iopub.status.idle": "2022-01-05T16:44:55.644137Z",
     "shell.execute_reply": "2022-01-05T16:44:55.644506Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rnn, losses = train_rnn(data_train, num_steps=500)\n",
    "\n",
    "plt.plot([i for i in range(len(losses))], losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8000ce49",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you did everything correctly, the loss should have converged to below 0.075:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52299273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.654456Z",
     "iopub.status.busy": "2022-01-05T16:44:55.653976Z",
     "iopub.status.idle": "2022-01-05T16:44:55.662951Z",
     "shell.execute_reply": "2022-01-05T16:44:55.662553Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assert torch.mean(torch.tensor(losses[-25:])) < 0.075"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2b9bd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Evaluation on the test set\n",
    "\n",
    "Let us now use the network to predict the samples in the test set and plot predicted versus true value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d90f1dca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.672500Z",
     "iopub.status.busy": "2022-01-05T16:44:55.671819Z",
     "iopub.status.idle": "2022-01-05T16:44:55.680928Z",
     "shell.execute_reply": "2022-01-05T16:44:55.679950Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ys = []\n",
    "y_hats = []\n",
    "\n",
    "for i in range(len(data_test) - 24):\n",
    "    x = data_test[i: i + 24]\n",
    "    y = data_test[i + 24, 1]\n",
    "    _, y_hat = rnn(x)\n",
    "\n",
    "    ys.append(float(y))\n",
    "    y_hats.append(float(y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8acd754b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-05T16:44:55.690785Z",
     "iopub.status.busy": "2022-01-05T16:44:55.690105Z",
     "iopub.status.idle": "2022-01-05T16:44:55.697590Z",
     "shell.execute_reply": "2022-01-05T16:44:55.697196Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(ys, y_hats)\n",
    "plt.axline((1, 1), slope=1, c='black')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

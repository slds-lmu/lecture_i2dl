{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd8cfabd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 11\n",
    "\n",
    "Hüseyin Anil Gündüz\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bea88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from typing import List, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "from torch import nn, Tensor\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import Adam, Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "set_matplotlib_formats('png', 'pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4b4157",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "In this exercise we will get acquainted with the KL divergence for normal distributions.\n",
    "First, let $p(x)=\\mathcal{N}(\\mu_1,\\sigma_1^2)$ and $q(x)=\\mathcal{N}(\\mu_2,\\sigma_2^2)$\n",
    "and show that\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{KL}(q||p)\n",
    "= \\mathbb{E}_{x\\sim q}\\left[\\log\\frac{q(x)}{p(x)}\\right]\n",
    "=\\log\\frac{\\sigma_1}{\\sigma_2}+\\frac{\\sigma_2^2+(\\mu_1-\\mu_2)^2}{2\\sigma_1^2} -\\frac 1 2\n",
    "\\end{equation}\n",
    "\n",
    "Now, consider a variational autoencoder that takes a vector as input $\\textbf{x}$ and\n",
    "transforms it into a mean vector $\\mu(\\textbf{x})$ and a variance vector $\\sigma(\\textbf{x})^2$.\n",
    "From these, we derive the latent code $\\textbf{z}\\sim q(\\textbf{z})=\\mathcal{N}(\\mu(\\textbf{x}),\\text{diag}(\\sigma(\\textbf{x})^2))$,\n",
    "i.e. a multivariate Gaussian in $d$ dimensions with a given mean vector and diagonal\n",
    "covariance matrix. The prior distribution for $\\textbf{z}$ is another $d$-dimensional\n",
    "multivariate Gaussian $p=\\mathcal{N}(\\textbf{0},\\textbf{1})$.\n",
    "\n",
    "Now show that:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{KL}(q||p)= -\\frac 1 2 \\sum_{i=1}^d \\left(1+\\log\\sigma_i(\\textbf{x})^2-\\sigma_i(\\textbf{x})^2 - \\mu_i(\\textbf{x})^2 \\right)\n",
    "\\end{equation}\n",
    "\n",
    "Hint: start by showing that $p$ and $q$ can be factorized into a product of independent\n",
    "Gaussian components, one for each dimension, then apply the formula for the KL\n",
    "divergence for the univariate case.\n",
    "\n",
    "\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "In this exercise we are going to implement variational autoencoders (VAEs) on the MNIST\n",
    "dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf4a02",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x = MNIST(root='.data', download=True, transform=ToTensor());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba6eef",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In a VAE, the encoder outputs mean and variance of a multivariate Gaussian distribution\n",
    "of the latent codes. Nothing prevents you from using a more complicated distribution in\n",
    "the same framework, but this is the usual choice. The expected log likelihood is then\n",
    "approximated by decoding a single sample from this distribution. Moreover, since we need\n",
    "the model to be differentiable end-to-end, sampling from the latent codes is\n",
    "re-formulated via the reparametrization trick.\n",
    "\n",
    "In the following we define a custom VAE module with a few utility functions that allow\n",
    "convenient managing of the VAE functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95875e0f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "\n",
    "    # We pass the encoder and decoder over the constructor, which gives us more flexibility.\n",
    "    def __init__(\n",
    "            self,\n",
    "            encoder: nn.Module,\n",
    "            decoder: nn.Module,\n",
    "            device: torch.device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder.to(device)\n",
    "        self.decoder = decoder.to(device)\n",
    "        self.device = device\n",
    "\n",
    "        # We need a normal distribution for the reparametrization trick\n",
    "        self.distribution = Normal(0, 1)\n",
    "\n",
    "    # We define a utility function for sampling the eps with correct shape and device\n",
    "    def sample_eps(self, sample_shape: Tuple) -> Tensor:\n",
    "        sampled_eps: Tensor = self.distribution.sample(sample_shape)\n",
    "        if str(self.device) != 'cpu':\n",
    "            sampled_eps = sampled_eps.cuda()\n",
    "        return sampled_eps\n",
    "\n",
    "    # We output the reconstructed x as well as the latent mu and log variance.\n",
    "    def forward(self, x: Tensor) -> Tuple[Tensor, Tensor, Tensor]:\n",
    "        mu, log_var = self.encoder(x)\n",
    "# TODO: Generate a sample z via the reparametrization trick.\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat, mu, log_var\n",
    "\n",
    "    # We define an inference method for encoding input tensors.\n",
    "    def encode(self, x: Tensor) -> Tensor:\n",
    "        with torch.no_grad():\n",
    "# TODO: Obtain mu.\n",
    "        return mu\n",
    "\n",
    "    # We define an inference method for reconstructing z tensors.\n",
    "    def reconstruct(self, z: Tensor) -> Tensor:\n",
    "        with torch.no_grad():\n",
    "# TODO: Obtain x hat.\n",
    "        return x_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08f837",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, we create our encoder and decoder.\n",
    "The encoder will have two outputs, which is easily done via the `nn.Module` container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b0ca7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size: int, latent_size: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "# TODO: Add a few fully connected layers and activation functions.\n",
    "# TODO: Choose an appropriate complex model. The output dimension should be 64.\n",
    "        )\n",
    "\n",
    "        self.mu = nn.Sequential(\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=32, out_features=latent_size),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "        self.log_var = nn.Sequential(\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(in_features=32, out_features=latent_size),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        x = self.net(x)\n",
    "        return self.mu(x), self.log_var(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size: int, latent_size: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "# TODO: Add a few fully connected layers and activation functions.\n",
    "# TODO: Choose an appropriate complex model.\n",
    "        )\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tuple[Tensor, Tensor]:\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c24cad",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "A missing component is a Kullback-Leibler loss function, which we will define\n",
    "now for two Gaussians:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1f09c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class KLDivergence:\n",
    "    def __call__(self, mu: Tensor, log_var: Tensor) -> Tensor:\n",
    "        return (\n",
    "# TODO: Compute the KL Loss for a batch of mus and log vars.\n",
    "# TODO: Use the VAE object to compress/reconstruct x\n",
    "# TODO: Compute the reconstruction batch_loss per sample\n",
    "# TODO: Compute the batch KL divergence\n",
    "# Hint: Divide the obtained KL loss by the number of pixels (for correct KL scale)\n",
    "# TODO: Compute the total loss\n",
    "# TODO: Do the backward pass and apply optimizer\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('TRAINING BATCH:\\t({:5} / {:5})\\tREC LOSS:\\t{:2.3f}\\tKL LOSS:\\t{:2.3f}'\n",
    "                      .format(batch_idx, num_train_batches, float(batch_rec_loss), float(batch_kl_loss)), end='\\r')\n",
    "\n",
    "            total_ep_loss += float(total_loss)\n",
    "\n",
    "        train_losses.append(total_ep_loss / num_train_batches)\n",
    "        print('EPOCH:\\t{:5}\\tTRAIN LOSS:\\t{:.3f}'.format(ep, train_losses[-1], end='\\r'))\n",
    "\n",
    "    return train_losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d157626",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we can initialize all our classes and start the training!\n",
    "We will choose a latent size of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e92664",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "latent_size = 8\n",
    "epochs = 2\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "encoder = (\n",
    "# TODO: Create an encoder.\n",
    ")\n",
    "\n",
    "decoder = (\n",
    "# TODO: Create a decoder.\n",
    ")\n",
    "\n",
    "vae = (\n",
    "# TODO: Create a VAE object.\n",
    ")\n",
    "\n",
    "optimizer = (\n",
    "# TODO: Define an optimizer.\n",
    ")\n",
    "\n",
    "train_autoencoder(vae, optimizer, train_x, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5052cf",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us check the reconstruction of a digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e1a16e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_reconstruction_grid(vae: nn.Module, mnist_dataset: MNIST) -> None:\n",
    "    x_samples = mnist_dataset.data[:100] / 255\n",
    "    z = vae.encode(x_samples.to(vae.device).view(100, -1))\n",
    "    x_hat = vae.reconstruct(z).detach().cpu().view(100, 28, 28)\n",
    "\n",
    "    cur_col = 0\n",
    "    image_list = []\n",
    "    for _ in range(4):\n",
    "        image_list.extend(x_samples[cur_col:cur_col + 25])\n",
    "        image_list.extend(x_hat[cur_col:cur_col + 25])\n",
    "        cur_col += 25\n",
    "\n",
    "    image_batch = torch.stack(image_list).unsqueeze(1)\n",
    "    image_grid = make_grid(image_batch, nrow=25)\n",
    "    plt.imshow(image_grid.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70317850",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_reconstruction_grid(vae, train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e7f8f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is already quite good for only two training epochs!\n",
    "Now try to remove the division of the KL by 784, train again and visualize the result.\n",
    "\n",
    "You should see a gray blob that looks a bit like the average of many digits.\n",
    "This phenomenon is named _mode collapse_, i.e. the distribution of the generator\n",
    "collapsed to a single mode that covers the entire dataset, instead of (at least)\n",
    "one mode for every digit. In VAEs, this is typically caused by a KL term that is\n",
    "very strong at the beginning of training, and dominates the reconstruction loss.\n",
    "The optimizer will focus most of its efforts to reduce this term, ending up in a poor local minimum.\n",
    "\n",
    "A popular method to deal with this issue is _KL annealing_.\n",
    "It consists in training the network without the KL regularizer for some time, then slowly\n",
    "increasing the weight of the KL. This procedure allows the network to first learn how to\n",
    "perform good reconstructions, then to adjust the latent code to conform to a Normal\n",
    "distribution without erasing progress on the reconstruction.\n",
    "\n",
    "To implement this behaviour, we define a small object that is able to return the\n",
    "desired KL weight in the respective epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7304b43d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class KLWeightManager:\n",
    "    \"\"\"\n",
    "    Manager to get the desired KL weight.\n",
    "\n",
    "    Warm up rounds specify the starting epochs until which the KL weight will be zero.\n",
    "    The annealing rounds describe the duration of the annealing process.\n",
    "    E.g., warm up is 5 and and there are 10 annealing rounds, then the first 5 epochs\n",
    "    will have a KL weight of 0 and from epoch 5 to 15 the weight will be annealed to 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, warm_up_rounds: int, annealing_rounds: int):\n",
    "        self.warm_up = warm_up_rounds\n",
    "        self.annealing_rounds = annealing_rounds\n",
    "\n",
    "\n",
    "    def __call__(self, cur_epoch: int) -> float:\n",
    "        if cur_epoch < self.warm_up:\n",
    "            return 0.0\n",
    "        elif cur_epoch >= self.warm_up + self.annealing_rounds:\n",
    "            return 1.0\n",
    "        else:\n",
    "            progress = cur_epoch - self.warm_up\n",
    "            return progress / self.annealing_rounds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa2e08a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's remove the scaling term in the training loop and integrate the `KLWeightManager`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3447b62",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_autoencoder(\n",
    "        vae: VAE,\n",
    "        optimizer: Optimizer,\n",
    "        mnist_dataset: MNIST,\n",
    "        epochs: int,\n",
    "        batch_size: int,\n",
    ") -> List[float]:\n",
    "\n",
    "    rec_loss = nn.MSELoss(reduction='sum')\n",
    "    kl_loss = KLDivergence()\n",
    "    kl_weighting = KLWeightManager(warm_up_rounds=0, annealing_rounds=5)\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    num_train_batches = ceil(len(mnist_dataset) / batch_size)\n",
    "    train_loader = DataLoader(mnist_dataset, batch_size, shuffle=True)\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        total_ep_loss = 0\n",
    "\n",
    "        for batch_idx, (x, _) in enumerate(train_loader):\n",
    "            x = x.to(vae.device).view(x.shape[0], -1)\n",
    "\n",
    "# TODO: Use the VAE object to compress/reconstruct x\n",
    "# TODO: Compute the reconstruction batch_loss per sample\n",
    "# TODO: Compute the batch KL divergence\n",
    "# TODO: Obtain the KL weight and reweight the KL loss\n",
    "# TODO: Compute the total loss\n",
    "# TODO: Do the backward pass and apply optimizer\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('TRAINING BATCH:\\t({:5} / {:5})\\tREC LOSS:\\t{:2.3f}\\tKL LOSS:\\t{:2.3f}'\n",
    "                      .format(batch_idx, num_train_batches, float(batch_rec_loss), float(batch_kl_loss)), end='\\r')\n",
    "\n",
    "            total_ep_loss += float(total_loss)\n",
    "\n",
    "        train_losses.append(total_ep_loss / num_train_batches)\n",
    "        print('EPOCH:\\t{:5}\\tTRAIN LOSS:\\t{:.3f}\\tKL WEIGHT:\\t{:.2f}'\n",
    "              .format(ep, train_losses[-1], kl_weighting(ep), end='\\r'))\n",
    "\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a41731e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "latent_size = 8\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "encoder = (\n",
    "# TODO: Create an encoder.\n",
    ")\n",
    "\n",
    "decoder = (\n",
    "# TODO: Create a decoder.\n",
    ")\n",
    "\n",
    "vae = (\n",
    "# TODO: Create a VAE object.\n",
    ")\n",
    "\n",
    "optimizer = (\n",
    "# TODO: Define an optimizer.\n",
    ")\n",
    "\n",
    "losses = train_autoencoder(vae, optimizer, train_x, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbfd8dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_reconstruction_grid(vae, train_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b6d415",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems like we don't suffer from posterior collaps and our reconstructions look rather\n",
    "good. It has been shown, that choosing KL weights larger than one can lead to overall\n",
    "better representations with the downside of worse reconstructions. This framework is\n",
    "found in literatures as $\\beta$-VAE. The correct choice of the KL weight is a difficult\n",
    "one and depends on the distribution of your dataset and also its dimensionality.\n",
    "\n",
    "With a VAE we also have a generative model. We could e.g. sample zs from a uniform range\n",
    "and see what the generator will reconstruct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baa229b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rand_z = torch.rand((100, latent_size), device=vae.device)\n",
    "generated_samples = vae.reconstruct(rand_z).view(100, 1, 28, 28).detach().cpu()\n",
    "\n",
    "image_grid = make_grid(generated_samples, nrow=25)\n",
    "plt.imshow(image_grid.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75381b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can also use the generative decoder to smoothly interpolate between random samples:\n",
    "(Execute the cell a few times to see the interpolation between other random digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1eb8e0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def interpolate_linear(x: Tensor, y: Tensor, steps: int,) -> Tensor:\n",
    "    cur_weight = 0.0\n",
    "    weight_incr = 1 / (steps - 1)\n",
    "\n",
    "    result = torch.zeros((steps, *x.shape))\n",
    "    if x.is_cuda:\n",
    "        result = result.cuda()\n",
    "\n",
    "    for step in range(steps):\n",
    "        result[step] = torch.lerp(x, y, cur_weight)\n",
    "        cur_weight += weight_incr\n",
    "\n",
    "    return result\n",
    "\n",
    "x_one = train_x.data[torch.randint(0, 60000, (1,))] / 255.\n",
    "z_one = vae.encode(x_one.view(1, -1).to(vae.device))\n",
    "\n",
    "x_two = train_x.data[torch.randint(0, 60000, (1,))] / 255.\n",
    "z_two = vae.encode(x_two.view(1, -1).to(vae.device))\n",
    "\n",
    "zs = interpolate_linear(z_one, z_two, steps=20)\n",
    "x_hats = vae.reconstruct(zs).view(20, 1, 28, 28).detach().cpu()\n",
    "\n",
    "image_grid = make_grid(x_hats, nrow=20)\n",
    "plt.imshow(image_grid.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

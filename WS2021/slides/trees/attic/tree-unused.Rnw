\begin{vbframe}{Impurity Measures}
\begin{itemize}
\item In general the three proposed splitting criteria are quite similar.
\item Entropy and Gini index are more sensitive to changes in the node probabilities.
-\item \textbf{Example:} two-class problem with 400 obs in each class and two possible splits:
\end{itemize}
-\begin{columns}[T,onlytextwidth]
column{0.5\textwidth}
\begin{center}
\textbf{Split 1:} \\
\vspace{0.25cm}
<<split1>>=
class = as.factor(c(rep(0,400), rep(1,400)))
x1 = as.factor(c(rep(0,300), rep(1,400), rep(0,100)))
x2 = as.factor(c(rep(0,600), rep(1,200)))
tab = table(x1, class)
tab2 = table(x2, class)
rownames(tab) = c("Left node", "Right node")
rownames(tab2) = c("Left node", "Right node")
kable(tab, row.names = TRUE, col.names = c("class A", "class B"))
@
\end{center}
\column{0.5\textwidth}
\begin{center}
\textbf{Split 2:} \\
\vspace{0.25cm}
<<split2>>=
kable(tab2, row.names = TRUE, col.names = c("class A", "class B"))
@
\end{center}
\end{columns}

\framebreak
\begin{columns}[T,onlytextwidth]
\column{0.5\textwidth}
\begin{center}
\textbf{Split 1:} \\
\vspace{0.25cm}
<<split1-2>>=
kable(tab, row.names = TRUE, col.names = c("class A", "class B"))
@
\end{center}
\column{0.5\textwidth}
\begin{center}
\textbf{Split 2:} \\
\vspace{0.25cm}
<<split2-2>>=
kable(tab2, row.names = TRUE, col.names = c("class A", "class B"))
@
\end{center}
\end{columns}

\begin{itemize}
\item Both splits produce a misclassification rate of $\frac{200}{800}=0.25$
\item Split 2 produces a pure node and is probably preferable.
\item The average node impurity for Split 1 is $0.375$ (Gini) or $0.406$ (Entropy) 
\item The average node impurity for Split 2 is $\frac{1}{3}$ (Gini) or $0.344$ (Entropy)
% Gini: 6/8 * 2 * 1/3 * 2/3
% entropy: 6/8 * ((1/3 * log(1/3) + 2/3 * log(2/3)) / (2 * log(0.5)))
\item Both criteria prefer split 2 and \textit{choose} the result with a pure node.
\end{itemize}
\framebreak
\begin{itemize}
\item For metric features the exact split points can be ambiguous.
\item If the classes of the response (for classification trees) are completely separated in the value range of the feature, a split can be done anywhere between the extreme valuess of the feature in the classes and the impurity measures stay the same.
\item Look again at the Iris data and the classes \textit{setosa} and \textit{versicolor}:
\end{itemize}
<<iris-rpart-plot, results='hide', fig.height=3>>=
# Trees on Iris Data
iristask = makeClassifTask(data = iris[,-(1:2)], target = "Species")

rpart = makeLearner("classif.rpart")
rpart = setHyperPars(rpart, cp = 0, minbucket=4, maxdepth=1) #Illustration
model = train(rpart, iristask)
# Plot
plotLearnerPrediction(rpart, iristask, gridsize = 300, cv = 0) +
  scale_f_d() 
@
\end{vbframe}
 



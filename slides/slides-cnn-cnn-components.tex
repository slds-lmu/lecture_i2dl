\input{../../style/preamble4tex}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\input{../../latex-math/ml-nn}

\newcommand{\titlefigure}{figure/stride4.png}
%modify picture
\newcommand{\learninggoals}{
  \item Input Channel
  \item Padding
  \item Stride
  \item Pooling

}

\title{Deep Learning}
\date{}



\begin{document}

\lecturechapter{CNN Components}
\lecture{I2DL}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frametitle{Input Channel}

\begin{vbframe}{Input Channel}
         \begin{figure}
    \centering
    \includegraphics[width=4cm]{figure/gray.png}
  \end{figure}
    \begin{itemize}
    
       \item An image consists of the smallest indivisible segments called pixels and every pixel has a strength often known as the pixel intensity. 
       
       \item A grayscale image has a single input channel and value of each pixel represents the amount of light.
       
       \item Note a grayscale value can lie between 0 to 255, where 0 value corresponds to black and 255 to white.
       
       
    \end{itemize}

\end{vbframe}

\begin{vbframe}

 \begin{figure}
    \centering
    \includegraphics[width=7cm]{figure/RGB.jpeg}
  \end{figure}

 \begin{figure}
    \centering
    \includegraphics[width=5cm]{figure/RGB-1.png}
    \caption{\tiny Image source: Computer Vision Primer: How AI Sees An Imag eKishan Maladkar's Blog)}
  \end{figure}

\begin{itemize}
       \item A colored digital image usually comes with three color channels, i.e. the Red-Green-Blue channels, popularly known as the RGB values.   
        \item Each pixel can be represented by a vector of three numbers (each ranging from 0 to 255) for the three primary color channels.
      
%\end{itemize}
% \begin{figure}
%    \centering
%    \includegraphics[width=5cm]{figure/1channel.png}
%    \caption{\tiny CNNs takes grayscale image as input.}
%  \end{figure}


% \begin{figure}
%    \centering
%    \includegraphics[width=5cm]{figure/3channel.png}
%    \caption{\tiny CNNs use colored images where each of the Red, Green and Blue (RGB) color spectrums serve as input. (source: Chaitanya Belwal's Blog)}
%  \end{figure}
  
  
\end{vbframe}
\begin{vbframe}

 \begin{figure}
    \centering
    \includegraphics[width=5cm]{figure/3channel.png}
  \end{figure}

In this CNN:
    \begin{itemize}
       \item there are 3 input channel, with the size of 4x4 as an input matrices, 
       \item one 2x2 filter (also known as kernel), 
       \item a single ReLu layer,
       \item a single pooling layer (which applies the MaxPool function),
       \item and a single fully connected (FC) layer.
    \end{itemize}

    \begin{itemize}
       \item The elements of the filter matrix are equivalent to the unit weights in a standard NN and will be updated during the backpropagation phase.
       \item Assuming a stride of 2 with no padding, the output size of the convolution layer is determined by the following equation:
       \item $ O = \frac{I - K + 2.P}{S} + 1$ where: 
    \begin{itemize}
       \item O: is the dimension (rows and columns) of the output square matrix, 
       \item I: is the dimension (rows and columns) of the input square matrix,
       \item K: is the dimension (rows and columns) of the filter (kernel) square matrix, 
       \item P: is the number of pixels(cells) of padding added to each side of the input,
       \item S: is the stride, or the number of cells skipped each time the kernel is slided.
    \end{itemize}
    \end{itemize}

 \begin{figure}
    \centering
    \includegraphics[width=5cm]{figure/3channel.png}
  \end{figure}

Inserting the values shown in the figure into the equation,

\begin{align} 
O= \frac{I - K + 2.P}{S} + 1&={(4 - 2 + 2.0)\over 2} + 1\\ 
&=2 
\end{align}

\end{vbframe}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55%%

\begin{frame}{Valid Padding}

\begin{itemize}
%\only<1-3>{\item \enquote{Valid} convolution without padding.}
\only<1>{\item[] Suppose we have an input of size $5 \times 5$ and a filter of size $2 \times 2$. }
\only<2>{\item[] The filter is only allowed to move inside of the input space.}
\only<3>{\item[] That will inevitably reduce the output dimensions.}
\end{itemize}
\center
\only<1>{\scalebox{0.5}{\includegraphics{figure/padding1.png}}}%
\only<2>{\scalebox{0.5}{\includegraphics{figure/padding2.png}}}%
\only<3>{\scalebox{1}{\includegraphics{figure/padding3.png}}}%
\only<3>{\item[] In general, for an input of size $i \:(\times \:i)$ and filter size $k \:(\times \:k)$, the size of the output feature map $o \:(\times \:o)$ claculated by:
    $$ o=  i-k + 1 $$ }
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Same Padding}
\begin{itemize}
%\only<1-4>{\item Convolution with \enquote{same} padding.}
\only<1>{\item[] Suppose the following situation: an input with dimensions $5 \times 5$ and a filter with size $3 \times 3$.}
\only<2>{\item[] We would like to obtain an output with the same dimensions as the input.}
\only<3>{\item[] Hence, we apply a technique called zero padding. That is to say \enquote{pad} zeros around the input:}
\only<4>{\item[] That always works! We just have to adjust the zeros according to the input dimensions and filter size (ie. one, two or more rows).}

  \end{itemize}
  \center
  \only<1>{\includegraphics[width=5cm]{figure/padding4.png}}%
  \only<2>{\includegraphics[width=8cm]{figure/padding5.png}}%
  \only<3>{\includegraphics[width=8cm]{figure/padding6.png}}%
  \only<4>{\includegraphics[width=11cm]{figure/padding7.png}}%
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Padding and Network Depth}
\begin{figure}
\center
\scalebox{0.58}{\includegraphics{figure/zeropadding.png}}
\caption{\small{\enquote{Valid} versus \enquote{same} convolution. \emph{Top} : Without padding, the width of the feature map shrinks rapidly to 1 after just three convolutional layers (filter width of 6 shown in each layer). This limits how deep the network can be made. {Bottom} : With zero padding (shown as solid circles), the feature map can remain the same size after each convolution which means the network can be made arbitrarily deep. (Goodfellow, \emph{et al.}, 2016, ch.~9)}}
\end{figure}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Strides}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{

\frametitle{Strides}

  \begin{itemize}

    \only<1-3>{\item Stepsize \enquote{strides} of our filter (stride = 2 shown below).}

  \end{itemize}

  \center
  \only<1>{\scalebox{0.4}{\includegraphics{figure/stride1.png}}}%
  \only<2>{\scalebox{0.35}{\includegraphics{figure/stride2.png}}}%
  %\only<3>{\includegraphics[width=9cm]{plots/05_conv_variations/strides/strides2.png}}%
  %\only<4>{\includegraphics[width=9cm]{plots/05_conv_variations/strides/strides3.png}}%
  \only<3>{\scalebox{0.7}{\includegraphics[width=9cm]{figure/stride3.png}}}%
  
  \only<3>{\item[] In general, when there is no padding, for an input of size $i$, filter size $k$ and stride $s$, the size $o$ of the output feature map is:
    $$ o=\left\lfloor\frac{i-k}{s}\right\rfloor+ 1 $$ }

}

\frame{

\frametitle{Strides and downsampling}

\begin{figure}
\center
\includegraphics[width=.5\textwidth]{figure/stride4.png}
\caption{A strided convolution is equivalent to a convolution without strides followed by downsampling (Goodfellow, \emph{et al.}, 2016, ch.~9).}
\end{figure}


}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{frame}{Max Pooling}
\center
\only<1>{\includegraphics[width=10cm]{figure/maxpool1.png}}
\only<2>{\includegraphics[width=10cm]{figure/maxpool2.png}}
\only<3>{\includegraphics[width=10cm]{figure/maxpoolend.png}}
\begin{itemize}
\only<1>{\item We've seen how convolutions work, but there is one other operation we need to understand.}
\only<1>{\item We want to downsample the feature map but optimally lose no information.}
\only<2>{\item Applying the max pooling operation, we simply look for the maximum value at each spatial location.}
\only<2>{\item That is 8 for the first location.}
\only<2>{\item Due to the filter of size 2 we have the dimensions of the original feature map and obtain downsampling.}
\only<3>{\item The final pooled feature map has entries 8, 6, 9 and 3.
\only<3>{\item Max pooling brings us 2 properties: 1) dimention reduction and 2) spatial invariance.}
\item Popular pooling functions: max and (weighted) average.}
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Average Pooling}
\center
\only<1>{\includegraphics[width=10cm]{figure/avgpool1.png}}%
\only<2>{\includegraphics[width=10cm]{figure/avgpool2.png}}%
\only<3>{\includegraphics[width=10cm]{figure/avgpool3.png}}%
\only<4>{\includegraphics[width=10cm]{figure/avgpool4.png}}%

\begin{itemize}
\only<1>{\item We've seen how max pooling worked, there are exists other pooling operation such as avg pooling, fractional pooling, LP pooling, softmax pooling, stochastic pooling, blur pooling, global average pooling, and etc.}
\only<1>{\item Similar to max pooling, we downsample the feature map but optimally lose no information.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\only<2>{\item Applying the average pooling operation, we simply look for the mean/average value at each spatial location.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\only<3>{\item We use all information by Sum and backpropagated to all responses. }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\only<3>{\item It is not robust to noise. }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\only<4>{\item The final pooled feature map has entries 3.75, 2.5, 4.25 and 1.75. }
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{vbframe}{Comparison of Max and Average Pooling}
\begin{itemize}
\item Avg pooling use all information by sum but max pooling use only highest value.
\item In max pooling operation details are removed therefore it is suitable for sparse information (Image Classification) and avg pooling is suitable for dense information (NLP). 
\end{itemize}
\begin{figure}
\centering
\includegraphics[width=5cm]{figure/pooling.png}
\caption{Shortcomings of max and average pooling using Toy Image (photo source: https://iq.opengenus.org/maxpool-vs-avgpool/)}
\end{figure}
\end{vbframe}



\endlecture
\end{document}
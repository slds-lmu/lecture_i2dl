\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}
\input{../../latex-math/ml-nn}

\newcommand{\titlefigure}{figure/stride4.png}
%modify picture
\newcommand{\learninggoals}{
  \item Input Channel
  \item Padding
  \item Stride
  \item Pooling

}

\title{Deep Learning}
\date{}



\begin{document}

\lecturechapter{CNN Components}
\lecture{I2DL}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frametitle{Input Channel}

\begin{vbframe}{Input Channel}
         \begin{figure}
    \centering
    \includegraphics[width=4cm]{figure/gray.png}
        \caption{Left: image of Lincoln; Center: pixels labeled with grayscale values; Right: grayscale values by themselves (Levin \& Dorsey)}
  \end{figure}
    \begin{itemize}
    
       \item An image consists of the smallest indivisible segments called pixels with a strength often known as the pixel intensity. 
       
       \item A grayscale image has a single input channel with the value of each pixel representing the amount of light/brightness in the pixel.
       
       \item A grayscale value can lie between 0 and 255 (0 = black, 255 = white).
       
       
    \end{itemize}

\end{vbframe}

\begin{vbframe}

 \begin{figure}
    \centering
    \includegraphics[width=7cm]{figure/RGB.jpeg}
  \end{figure}

 \begin{figure}
    \centering
    \includegraphics[width=5cm]{figure/RGB-1.png}
    \caption{How AI sees an image (Maladkar, 2020)}
  \end{figure}

\begin{itemize}
       \item A colored digital image usually comes with three color channels, i.e. the Red-Green-Blue channels, popularly known as the RGB values.   
        \item Each pixel can be represented by a vector of three numbers (each ranging from 0 to 255) for the three primary color channels.
\end{itemize}

% \begin{figure}
%    \centering
%    \includegraphics[width=5cm]{figure/1channel.png}
%    \caption{\tiny CNNs takes grayscale image as input.}
%  \end{figure}


% \begin{figure}
%    \centering
%    \includegraphics[width=5cm]{figure/3channel.png}
%    \caption{\tiny CNNs use colored images where each of the Red, Green and Blue (RGB) color spectrums serve as input. (source: Chaitanya Belwal's Blog)}
%  \end{figure}
  
  
\end{vbframe}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%55%%

\begin{frame}{Valid Padding}

\begin{itemize}
%\only<1-3>{\item \enquote{Valid} convolution without padding.}
\only<1>{\item[] Suppose we have an input of size $5 \times 5$ and a filter of size $2 \times 2$. }
\only<2>{\item[] The filter is only allowed to move inside of the input space.}
\only<3>{\item[] That will inevitably reduce the output dimensions.}
\end{itemize}
\center
\only<1>{\scalebox{0.5}{\includegraphics{figure/padding1.png}}}%
\only<2>{\scalebox{0.5}{\includegraphics{figure/padding2.png}}}%
\only<3>{\scalebox{1}{\includegraphics{figure/padding3.png}}}%
\only<3>{\item[] In general, for an input of size $i \:(\times \:i)$ and filter size $k \:(\times \:k)$, the size of the output feature map $o \:(\times \:o)$ claculated by:
    $$ o=  i-k + 1 $$ }
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Same Padding}
\begin{itemize}
%\only<1-4>{\item Convolution with \enquote{same} padding.}
\only<1>{\item[] Suppose the following situation: an input with dimensions $5 \times 5$ and a filter with size $3 \times 3$.}
\only<2>{\item[] We would like to obtain an output with the same dimensions as the input.}
\only<3>{\item[] Hence, we apply a technique called zero padding. That is to say \enquote{pad} zeros around the input:}
\only<4>{\item[] That always works! We just have to adjust the zeros according to the input dimensions and filter size (ie. one, two or more rows).}

  \end{itemize}
  \center
  \only<1>{\includegraphics[width=5cm]{figure/padding4.png}}%
  \only<2>{\includegraphics[width=8cm]{figure/padding5.png}}%
  \only<3>{\includegraphics[width=8cm]{figure/padding6.png}}%
  \only<4>{\includegraphics[width=11cm]{figure/padding7.png}}%
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Padding and Network Depth}
\begin{figure}
\center
\scalebox{0.4}{\includegraphics{figure/zeropadding.png}}
\caption{\small{\enquote{Valid} versus \enquote{same} convolution. 
\\ \emph{Top} : Without padding, the width of the feature map shrinks rapidly to 1 after just three convolutional layers (filter width of 6 shown in each layer). This limits how deep the network can be made. 
\\ \emph{Bottom} : With zero padding (shown as solid circles), the feature map can remain the same size after each convolution which means the network can be made arbitrarily deep (Goodfellow et al., 2016).}}
\end{figure}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Strides}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\frame{

\frametitle{Strides}

  \begin{itemize}

    \only<1-3>{\item Stepsize \enquote{strides} of our filter (stride = 2 shown below).}

  \end{itemize}

  \center
  \only<1>{\scalebox{0.4}{\includegraphics{figure/stride1.png}}}%
  \only<2>{\scalebox{0.35}{\includegraphics{figure/stride2.png}}}%
  %\only<3>{\includegraphics[width=9cm]{plots/05_conv_variations/strides/strides2.png}}%
  %\only<4>{\includegraphics[width=9cm]{plots/05_conv_variations/strides/strides3.png}}%
  \only<3>{\scalebox{0.7}{\includegraphics[width=9cm]{figure/stride3.png}}}%
  
  \only<3>{\item[] In general, when there is no padding, for an input of size $i$, filter size $k$ and stride $stride$, the size $o$ of the output feature map is:
    $$ o=\left\lfloor\frac{i-k}{stride}\right\rfloor+ 1 $$ }

}

\frame{

\frametitle{Strides and downsampling}

\begin{figure}
\center
\includegraphics[width=.5\textwidth]{figure/stride4.png}
\caption{A strided convolution is equivalent to a convolution without strides followed by downsampling (Goodfellow et al., 2016).}
\end{figure}


}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{frame}{Max Pooling}
\center
\only<1>{\includegraphics[width=10cm]{figure/maxpool1.png}}
\only<2>{\includegraphics[width=10cm]{figure/maxpool2.png}}
\only<3>{\includegraphics[width=10cm]{figure/maxpoolend.png}}
\begin{itemize}
\only<1>{\item We've seen how convolutions work, but there is one other operation we need to understand.}
\only<1>{\item We want to downsample the feature map but optimally lose no information.}
\only<2>{\item Applying the max pooling operation, we simply look for the maximum value at each spatial location.}
\only<2>{\item That is 8 for the first location.}
\only<2>{\item Due to the filter of size 2 we have the dimensions of the original feature map and obtain downsampling.}
\only<3>{\item The final pooled feature map has entries 8, 6, 9 and 3.
\only<3>{\item Max pooling brings us 2 properties: 1) dimention reduction and 2) spatial invariance.}
\item Popular pooling functions: max and (weighted) average.}
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}{Average Pooling}
\center
\only<1>{\includegraphics[width=10cm]{figure/avgpool1.png}}%
\only<2>{\includegraphics[width=10cm]{figure/avgpool2.png}}%
\only<3>{\includegraphics[width=10cm]{figure/avgpool3.png}}%
\only<4>{\includegraphics[width=10cm]{figure/avgpool4.png}}%

\begin{itemize}
\only<1>{\item We've seen how max pooling worked, there are exists other pooling operation such as avg pooling, fractional pooling, LP pooling, softmax pooling, stochastic pooling, blur pooling, global average pooling, and etc.}
\only<1>{\item Similar to max pooling, we downsample the feature map but optimally lose no information.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\only<2>{\item Applying the average pooling operation, we simply look for the mean/average value at each spatial location.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\only<3>{\item We use all information by sum and backpropagated to all responses. }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\only<3>{\item It is not robust to noise. }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\only<4>{\item The final pooled feature map has entries 3.75, 2.5, 4.25 and 1.75. }
\end{itemize}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{vbframe}{Comparison of Max and Average Pooling}
\begin{itemize}
\item Avg pooling use all information by sum but max pooling use only highest value.
\item In max pooling operation details are removed therefore it is suitable for sparse information (Image Classification) and avg pooling is suitable for dense information (NLP). 
\end{itemize}
\begin{figure}
\centering
\includegraphics[width=5cm]{figure/pooling.png}
\caption{Shortcomings of max and average pooling using toy image (Sharma, 2020)}
\end{figure}
\end{vbframe}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{vbframe}

 \begin{figure}
    \centering
    \includegraphics[width=5cm]{figure/3channel.png}
    \caption{For colored images each of the Red, Green and Blue (RGB) color spectrums serve as seperate input channel (Belwal, 2018)}
  \end{figure}

In this CNN:
    \begin{itemize}
       \item there are 3 input channel, with the size of 4x4 as an input matrices, 
       \item one 2x2 filter (also known as kernel), 
       \item a single ReLu layer,
       \item a single pooling layer (which applies the MaxPool function),
       \item and a single fully connected (FC) layer.
    \end{itemize}

    \begin{itemize}
       \item The elements of the filter matrix are equivalent to the unit weights in a standard NN and will be updated during the backpropagation phase.
       \item Assuming a stride of 2 with no padding, the output size of the convolution layer is determined by the following equation:
       \item $ o = \frac{i - k + 2p}{stride} + 1$ where: 
    \begin{itemize}
       \item o: is the dimension (rows and columns) of the output square matrix, 
       \item i: is the dimension (rows and columns) of the input square matrix,
       \item k: is the dimension (rows and columns) of the filter (kernel) square matrix, 
       \item p: is the number of pixels (cells) of padding added to each side of the input,
       \item stride: is the stride, or the number of cells skipped each time the kernel is slided.
    \end{itemize}
    \end{itemize}

 \begin{figure}
    \centering
    \includegraphics[width=5cm]{figure/3channel.png}
    %\caption{For colored images each of the Red, Green and Blue (RGB) color spectrums serve as seperate input channel (Belwal, 2018)}
  \end{figure}

Inserting the values shown in the figure into the equation,

\begin{align} 
o= \frac{i - k + 2p}{stride} + 1&={(4 - 2 + 2 \cdot 0)\over 2} + 1\\ 
&=2 
\end{align}

\end{vbframe}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%          REFERENCES          %%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{vbframe}
\frametitle{References}
\footnotesize{
\begin{thebibliography}{99}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibitem[(Levin \& Dorsey)]{1} Levin, G. (n.d.). \textit{Image Processing and Computer Vision}. ofBook - Image Processing and Computer Vision. \url{https://openframeworks.cc/ofBook/chapters/image_processing_computer_vision.html}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibitem[(Goodfellow et al., 2016)]{2} Ian Goodfellow, Yoshua Bengio, \& Aaron Courville (2016). \textit{Deep Learning}. MIT Press.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibitem[(Sharma, 2020)]{3} Sharma, P. (2020, April 21). \textit{MaxPool vs avgpool}. OpenGenus IQ: Computing Expertise \% Legacy. https://iq.opengenus.org/maxpool-vs-avgpool/ .
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibitem[(Belwal, 2018)]{4} Belwal, C. (2018, June 12). \textit{Part III: Backpropagation mechanics for a convolutional neural network}. Part III: Backpropagation mechanics for a Convolutional Neural Network. \url{http://cbelwal.blogspot.com/2018/05/part-iii-backpropagation-mechanics-for.html} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibitem[(Maladkar, 2020)]{5} Maladkar, K. (2020, October 16). \textit{Computer vision primer: How ai sees an image}. Analytics India Magazine. \url{https://analyticsindiamag.com/computer-vision-primer-how-ai-sees-an-image/} 
\end{thebibliography}
}
\end{vbframe}


\endlecture
\end{document}
